---
title: Infino
---

>[Infino](https://github.com/infinohq/infino) is an open-source observability platform that stores both metrics and application logs together.

Key features of `Infino` include:
- **Metrics Tracking**: Capture time taken by LLM model to handle request, errors, number of tokens, and costing indication for the particular LLM.
- **Data Tracking**: Log and store prompt, request, and response data for each LangChain interaction.
- **Graph Visualization**: Generate basic graphs over time, depicting metrics such as request duration, error occurrences, token count, and cost.

## Installation and Setup

First, you'll need to install the  `infinopy` Python package as follows:

<CodeGroup>
```bash pip
pip install infinopy
```

```bash uv
uv add infinopy
```
</CodeGroup>

If you already have an `Infino Server` running, then you're good to go; but if
you don't, follow the next steps to start it:

- Make sure you have Docker installed
- Run the following in your terminal:
    ```
    docker run --rm --detach --name infino-example -p 3000:3000 infinohq/infino:latest
    ```



## Using Infino

See a [usage example of `InfinoCallbackHandler`](/oss/python/integrations/callbacks/infino).

```python
from langchain.callbacks import InfinoCallbackHandler
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\python\integrations\providers\infino.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
