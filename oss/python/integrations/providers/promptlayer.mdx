---
title: PromptLayer
---

>[PromptLayer](https://docs.promptlayer.com/introduction) is a platform for prompt engineering.
> It also helps with the LLM observability to visualize requests, version prompts, and track usage.
>
>While `PromptLayer` does have LLMs that integrate directly with LangChain (e.g.
> [`PromptLayerOpenAI`](https://docs.promptlayer.com/languages/langchain)),
> using a callback is the recommended way to integrate `PromptLayer` with LangChain.

## Installation and Setup

To work with `PromptLayer`, we have to:
- Create a `PromptLayer` account
- Create an api token and set it as an environment variable (`PROMPTLAYER_API_KEY`)

Install a Python package:

<CodeGroup>
```bash pip
pip install promptlayer
```

```bash uv
uv add promptlayer
```
</CodeGroup>


## Callback

See a [usage example](/oss/python/integrations/callbacks/promptlayer).

```python
import promptlayer  # Don't forget this import!
from langchain.callbacks import PromptLayerCallbackHandler
```


## LLM

See a [usage example](/oss/python/integrations/llms/promptlayer_openai).

```python
from langchain_community.llms import PromptLayerOpenAI
```


## Chat Models

See a [usage example](/oss/python/integrations/chat/promptlayer_chatopenai).

```python
from langchain_community.chat_models import PromptLayerChatOpenAI
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\python\integrations\providers\promptlayer.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
