---
title: Azure AI
---

This page covers all LangChain integrations with [Microsoft Azure](https://azure.microsoft.com/) and its related projects.

Integration packages for Azure AI, Dynamic Sessions, SQL Server are maintained in
the [langchain-azure](https://github.com/langchain-ai/langchain-azure) repository.

## Chat models

We recommend developers start with the (`langchain-azure-ai`) to access all the models available in [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/model-catalog-overview).

### Azure AI chat completions

Access models like Azure OpenAI, DeepSeek R1, Cohere, Phi and Mistral using the `AzureAIChatCompletionsModel` class.

<CodeGroup>
```bash pip
pip install -U langchain-azure-ai
```

```bash uv
uv add langchain-azure-ai
```
</CodeGroup>

Configure your API key and Endpoint.

```bash
export AZURE_AI_CREDENTIAL=your-api-key
export AZURE_AI_ENDPOINT=your-endpoint
```

```python
from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel

llm = AzureAIChatCompletionsModel(
    model_name="gpt-4o",
    api_version="2024-05-01-preview",
)

llm.invoke('Tell me a joke and include some emojis')
```

## Embedding models

### Azure AI model inference for embeddings

<CodeGroup>
```bash pip
pip install -U langchain-azure-ai
```

```bash uv
uv add langchain-azure-ai
```
</CodeGroup>

Configure your API key and Endpoint.

```bash
export AZURE_AI_CREDENTIAL=your-api-key
export AZURE_AI_ENDPOINT=your-endpoint
```

```python
from langchain_azure_ai.embeddings import AzureAIEmbeddingsModel

embed_model = AzureAIEmbeddingsModel(
    model_name="text-embedding-ada-002"
)
```

## Vector stores

### Azure CosmosDB NoSQL Vector Search

> [Azure CosmosDB NoSQL](https://azure.microsoft.com/en-us/products/cosmos-db/) is a fully managed,
> globally distributed, serverless document database for modern applications. It stores data in flexible
> JSON documents and uses a SQL-like query language. This provides high performance, low latency, and automatic,
> elastic scalability. It also features integrated vector search capabilities for AI workloads
> like generative AI and RAG. This allows you to store, index, and query vector embeddings alongside
> your operational data in the same database. You can combine vector similarity search with traditional
> keyword-based search for relevant results and choose from various indexing methods for optimal performance.
> This unified approach simplifies application architecture and ensures data consistency.

We need to install the `azure-cosmos` package to use this vector store.

<CodeGroup>
    ```bash pip
    pip install -qU azure-cosmos
    ```

    ```bash uv
    uv add azure-cosmos
    ```
</CodeGroup>

```python
from langchain_azure_ai.vectorstores.azure_cosmos_db_no_sql import (
    AzureCosmosDBNoSqlVectorSearch,
)
vector_search = AzureCosmosDBNoSqlVectorSearch.from_documents(
    documents=docs,
    embedding=openai_embeddings,
    cosmos_client=cosmos_client,
    database_name=database_name,
    container_name=container_name,
    vector_embedding_policy=vector_embedding_policy,
    full_text_policy=full_text_policy,
    indexing_policy=indexing_policy,
    cosmos_container_properties=cosmos_container_properties,
    cosmos_database_properties={},
    full_text_search_enabled=True,
)
```

See a [usage example](/oss/python/integrations/vectorstores/azure_cosmos_db_no_sql).


### Azure CosmosDB Mongo vCore Vector Search

> [Azure CosmosDB Mongo vCore](https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/) architecture makes
it easy to create a database with full native MongoDB support. You can apply your MongoDB experience and continue
to use your favorite MongoDB drivers, SDKs, and tools by pointing your application to the API for MongoDB (vCore)
cluster's connection string.

We need to install the `pymongo` package to use this vector store.

<CodeGroup>
    ```bash pip
    pip install -qU pymongo
    ```

    ```bash uv
    uv add pymongo
    ```
</CodeGroup>

```python
from langchain_azure_ai.vectorstores.azure_cosmos_db_mongo_vcore import (
    AzureCosmosDBMongoVCoreVectorSearch,
)

vectorstore = AzureCosmosDBMongoVCoreVectorSearch.from_documents(
    docs,
    openai_embeddings,
    collection=collection,
    index_name=INDEX_NAME,
)
```

See a [usage example](/oss/python/integrations/vectorstores/azure_cosmos_db_mongo_vcore).

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\python\integrations\providers\azure_ai.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
