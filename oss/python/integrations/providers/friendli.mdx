---
title: Friendli AI
---

> [FriendliAI](https://friendli.ai/) enhances AI application performance and optimizes
> cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads.

## Installation and setup

Install the `friendli-client` python package.

<CodeGroup>
```bash pip
pip install -U langchain_community friendli-client
```

```bash uv
uv add langchain_community friendli-client
```
</CodeGroup>

Sign in to [Friendli Suite](https://suite.friendli.ai/) to create a Personal Access Token,
and set it as the `FRIENDLI_TOKEN` environment variable.


## Chat models

See a [usage example](/oss/python/integrations/chat/friendli).

```python
from langchain_community.chat_models.friendli import ChatFriendli

chat = ChatFriendli(model='meta-llama-3.1-8b-instruct')

for m in chat.stream("Tell me fun things to do in NYC"):
    print(m.content, end="", flush=True)
```

## LLMs

See a [usage example](/oss/python/integrations/llms/friendli).

```python
from langchain_community.llms.friendli import Friendli

llm = Friendli(model='meta-llama-3.1-8b-instruct')

print(llm.invoke("def bubble_sort(): "))
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\python\integrations\providers\friendli.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
