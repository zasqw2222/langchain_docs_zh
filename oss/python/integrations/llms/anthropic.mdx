---
title: AnthropicLLM
---


<Warning>
**You are currently on a page documenting the use of Anthropic legacy Claude 2 models as text completion models. The latest and most popular Anthropic models are [chat completion models](/oss/python/langchain/models), and the text completion models have been deprecated.**

You are probably looking for [this page instead](/oss/python/integrations/chat/anthropic/).
</Warning>

This example goes over how to use LangChain to interact with `Anthropic` models.

## Installation

```python
pip install -qU langchain-anthropic
```

## Environment Setup

We'll need to get an [Anthropic](https://console.anthropic.com/settings/keys) API key and set the `ANTHROPIC_API_KEY` environment variable:

```python
import os
from getpass import getpass

if "ANTHROPIC_API_KEY" not in os.environ:
    os.environ["ANTHROPIC_API_KEY"] = getpass()
```

## Usage

```python
from langchain_anthropic import AnthropicLLM
from langchain_core.prompts import PromptTemplate

template = """Question: {question}

Answer: Let's think step by step."""

prompt = PromptTemplate.from_template(template)

model = AnthropicLLM(model="claude-2.1")

chain = prompt | model

chain.invoke({"question": "What is LangChain?"})
```

```output
'\nLangChain is a decentralized blockchain network that leverages AI and machine learning to provide language translation services.'
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\python\integrations\llms\anthropic.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
