---
title: 持久化
---



LangGraph 通过检查点保存器实现了内置的持久化层。当您使用检查点保存器编译图时，保存器会在每个超级步骤保存图状态的 `checkpoint`。这些检查点会保存到一个 `thread` 中，可在图执行后访问。由于 `thread` 允许在执行后访问图的状态，多种强大能力成为可能，包括人在回路、记忆、时间旅行以及容错。下面我们将更详细地讨论每个概念。

![Checkpoints](/oss/images/checkpoints.jpg)

<Info>
**LangGraph API 会自动处理检查点**
使用 LangGraph API 时，您无需手动实现或配置检查点保存器。API 会在幕后为您处理所有持久化基础设施。
</Info>

## 线程

线程是检查点保存器为每个保存的检查点分配的唯一 ID 或线程标识符。它包含一系列[运行](/langsmith/assistants#execution)累计得到的状态。当执行一次运行时，助手底层图的[状态](/oss/python/langgraph/graph-api#state)会持久化到该线程中。

使用检查点保存器调用图时，您**必须**在配置的 `configurable` 部分中指定 `thread_id`。

```python
{"configurable": {"thread_id": "1"}}
```




可以检索线程的当前状态和历史状态。要持久化状态，必须在执行运行之前创建线程。LangSmith API 提供了多个用于创建和管理线程以及线程状态的端点。详情参见[API 参考](https://langchain-ai.github.io/langgraph/cloud/reference/api/)。

## 检查点

线程在某个特定时间点的状态称为检查点。检查点是每个超级步骤保存的图状态快照，由 `StateSnapshot` 对象表示，具有以下关键属性：

* `config`：与此检查点关联的配置。
* `metadata`：与此检查点关联的元数据。
* `values`：此时刻状态通道的值。
* `next`：图中下一步要执行的节点名称元组。
* `tasks`：包含即将执行任务信息的 `PregelTask` 对象元组。如果之前尝试过该步骤，任务中会包含错误信息；如果图在节点内部被[动态](/oss/python/langgraph/interrupts#pause-using-interrupt)中断，任务会包含与中断相关的额外数据。

检查点会被持久化，可用于日后恢复线程状态。

让我们看看以下简单图在调用时会保存哪些检查点：

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.runnables import RunnableConfig
from typing import Annotated
from typing_extensions import TypedDict
from operator import add

class State(TypedDict):
    foo: str
    bar: Annotated[list[str], add]

def node_a(state: State):
    return {"foo": "a", "bar": ["a"]}

def node_b(state: State):
    return {"foo": "b", "bar": ["b"]}


workflow = StateGraph(State)
workflow.add_node(node_a)
workflow.add_node(node_b)
workflow.add_edge(START, "node_a")
workflow.add_edge("node_a", "node_b")
workflow.add_edge("node_b", END)

checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}
graph.invoke({"foo": ""}, config)
```






运行该图后，我们预计会看到恰好 4 个检查点：

* 下一个执行节点为 [`START`](https://reference.langchain.com/python/langgraph/constants/#langgraph.constants.START) 的空检查点
* 包含用户输入 `{'foo': '', 'bar': []}` 且下一个执行节点为 `node_a` 的检查点
* 包含 `node_a` 输出 `{'foo': 'a', 'bar': ['a']}` 且下一个执行节点为 `node_b` 的检查点
* 包含 `node_b` 输出 `{'foo': 'b', 'bar': ['a', 'b']}` 且没有待执行节点的检查点

注意由于 `bar` 通道定义了 reducer，因此其值包含两个节点的输出。




### 获取状态

与保存的图状态交互时，您**必须**指定一个[线程标识符](#threads)。可以通过调用 `graph.get_state(config)` 查看图的_最新_状态。它将返回一个 `StateSnapshot` 对象，对应配置中提供的线程 ID 关联的最新检查点，或者该线程中指定 `checkpoint_id` 的检查点。

```python
# get the latest state snapshot
config = {"configurable": {"thread_id": "1"}}
graph.get_state(config)

# get a state snapshot for a specific checkpoint_id
config = {"configurable": {"thread_id": "1", "checkpoint_id": "1ef663ba-28fe-6528-8002-5a559208592c"}}
graph.get_state(config)
```




在我们的示例中，`get_state` 的输出如下：

```
StateSnapshot(
    values={'foo': 'b', 'bar': ['a', 'b']},
    next=(),
    config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28fe-6528-8002-5a559208592c'}},
    metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2},
    created_at='2024-08-29T19:19:38.821749+00:00',
    parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}}, tasks=()
)
```




### 获取状态历史

可以通过调用 [`graph.get_state_history(config)`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.get_state_history) 获取指定线程的完整图执行历史。它会返回与配置中线程 ID 关联的 `StateSnapshot` 对象列表。需要注意，检查点按时间顺序排列，最新的检查点 / `StateSnapshot` 位于列表第一位。

```python
config = {"configurable": {"thread_id": "1"}}
list(graph.get_state_history(config))
```




在我们的示例中，[`get_state_history`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.get_state_history) 的输出如下：

```
[
    StateSnapshot(
        values={'foo': 'b', 'bar': ['a', 'b']},
        next=(),
        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28fe-6528-8002-5a559208592c'}},
        metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2},
        created_at='2024-08-29T19:19:38.821749+00:00',
        parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}},
        tasks=(),
    ),
    StateSnapshot(
        values={'foo': 'a', 'bar': ['a']},
        next=('node_b',),
        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}},
        metadata={'source': 'loop', 'writes': {'node_a': {'foo': 'a', 'bar': ['a']}}, 'step': 1},
        created_at='2024-08-29T19:19:38.819946+00:00',
        parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f4-6b4a-8000-ca575a13d36a'}},
        tasks=(PregelTask(id='6fb7314f-f114-5413-a1f3-d37dfe98ff44', name='node_b', error=None, interrupts=()),),
    ),
    StateSnapshot(
        values={'foo': '', 'bar': []},
        next=('node_a',),
        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f4-6b4a-8000-ca575a13d36a'}},
        metadata={'source': 'loop', 'writes': None, 'step': 0},
        created_at='2024-08-29T19:19:38.817813+00:00',
        parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f0-6c66-bfff-6723431e8481'}},
        tasks=(PregelTask(id='f1b14528-5ee5-579c-949b-23ef9bfbed58', name='node_a', error=None, interrupts=()),),
    ),
    StateSnapshot(
        values={'bar': []},
        next=('__start__',),
        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f0-6c66-bfff-6723431e8481'}},
        metadata={'source': 'input', 'writes': {'foo': ''}, 'step': -1},
        created_at='2024-08-29T19:19:38.816205+00:00',
        parent_config=None,
        tasks=(PregelTask(id='6d27aa2e-d72b-5504-a36f-8620e54a76dd', name='__start__', error=None, interrupts=()),),
    )
]
```




![State](/oss/images/get_state.jpg)

### 重放

还可以回放之前的图执行。如果我们在 `invoke` 图时提供 `thread_id` 和 `checkpoint_id`，则会在该 `checkpoint_id` 对应的检查点之前_重放_已执行的步骤，并只执行检查点之后的步骤。

* `thread_id` 是线程的 ID。
* `checkpoint_id` 是引用线程中某个特定检查点的标识符。

调用图时必须在配置的 `configurable` 部分传入这些参数：

```python
config = {"configurable": {"thread_id": "1", "checkpoint_id": "0c62ca34-ac19-445d-bbb0-5b4984975b2a"}}
graph.invoke(None, config=config)
```




值得注意的是，LangGraph 会判断某个步骤是否已经执行过。如果执行过，LangGraph 仅 _重放_ 图中的该步骤而不会重新执行，但这仅针对提供的 `checkpoint_id` 之前的步骤。`checkpoint_id` 之后的所有步骤都会执行（即产生新的分支），即使它们之前执行过也是如此。有关重放的更多信息，请参阅[时间旅行操作指南](/oss/python/langgraph/use-time-travel)。

![Replay](/oss/images/re_play.png)

### 更新状态

除了从特定 `checkpoint` 重放图之外，我们还可以_编辑_图状态，可使用 [`update_state`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.update_state) 方法完成。它接受三个不同的参数：




#### `config`

配置应包含 `thread_id`，用于指定要更新的线程。仅传入 `thread_id` 时，我们会更新（或分叉）当前状态。可选地，如果包含 `checkpoint_id` 字段，则分叉该检查点。

#### `values`

这些值用于更新状态。请注意，此更新与节点产生的任何更新完全一致。这意味着如果图状态中某些通道定义了[reducer](/oss/python/langgraph/graph-api#reducers)，这些值会传递给对应的 reducer。因此，[`update_state`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.update_state) 并不会自动覆盖所有通道的值，只会覆盖没有 reducer 的通道。我们来看一个例子。

假设您用以下模式定义了图状态（详见上方示例）：

```python
from typing import Annotated
from typing_extensions import TypedDict
from operator import add

class State(TypedDict):
    foo: int
    bar: Annotated[list[str], add]
```




假设当前图状态为

```
{"foo": 1, "bar": ["a"]}
```




如果如下更新状态：

```python
graph.update_state(config, {"foo": 2, "bar": ["b"]})
```




则图的新状态为：

```
{"foo": 2, "bar": ["a", "b"]}
```

`foo` 键（通道）完全被替换（因为未为该通道指定 reducer，所以 [`update_state`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.update_state) 会覆盖它）。而 `bar` 键指定了 reducer，因此会在 `bar` 状态后追加 `"b"`。




#### `as_node`

调用 [`update_state`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.CompiledStateGraph.update_state) 时最后一个可选参数是 `as_node`。若提供该参数，更新将被视为来自节点 `as_node`。如果未提供，且最后一个更新状态的节点不唯一，则会自动设为最后更新的节点。之所以重要，是因为接下来要执行的步骤取决于最后一个发生更新的节点，因此可以借此控制下一次执行的节点。参阅[时间旅行操作指南](/oss/python/langgraph/use-time-travel)了解更多分叉状态的内容。




![Update](/oss/images/checkpoints_full_story.jpg)

## 存储（Memory Store）

![Model of shared state](/oss/images/shared_state.png)

[状态模式](/oss/python/langgraph/graph-api#schema)定义了一组在图执行时填充的键。如上所述，状态可以在每个图步骤中通过检查点保存器写入线程，实现状态持久化。

但如果我们希望在_不同线程之间_保留某些信息怎么办？想象一个聊天机器人场景，我们希望在与某位用户的_所有_聊天（线程）中保留该用户的特定信息。

仅靠检查点保存器无法跨线程共享信息，因此需要 [`Store`](https://reference.langchain.com/python/langgraph/store/) 接口。举例来说，我们可以定义一个 `InMemoryStore`，用于跨线程存储用户信息。与之前一样，我们在编译图时同时传入检查点保存器和新的 `in_memory_store` 变量即可。

<Info>
**LangGraph API 会自动处理 Store**
使用 LangGraph API 时，您无需手动实现或配置 Store。API 会在幕后为您处理所有存储基础设施。
</Info>

### 基本用法

首先，在不使用 LangGraph 的情况下单独演示。

```python
from langgraph.store.memory import InMemoryStore
in_memory_store = InMemoryStore()
```




记忆通过一个 `tuple` 进行命名空间，在此示例中为 `(<user_id>, "memories")`。命名空间长度和内容都可以任意定义，不一定与用户相关。

```python
user_id = "1"
namespace_for_memory = (user_id, "memories")
```




我们使用 `store.put` 方法将记忆保存到存储中的命名空间。调用时需要提供上述命名空间以及记忆的键值对：键是记忆的唯一标识符（`memory_id`），值（字典）是记忆本身。

```python
memory_id = str(uuid.uuid4())
memory = {"food_preference" : "I like pizza"}
in_memory_store.put(namespace_for_memory, memory_id, memory)
```




可以通过 `store.search` 方法读取该命名空间下的记忆，它会以列表形式返回给定用户的所有记忆。最新的记忆位于列表末尾。

```python
memories = in_memory_store.search(namespace_for_memory)
memories[-1].dict()
{'value': {'food_preference': 'I like pizza'},
 'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',
 'namespace': ['1', 'memories'],
 'created_at': '2024-10-02T17:22:31.590602+00:00',
 'updated_at': '2024-10-02T17:22:31.590605+00:00'}
```

每个记忆条目都是具有特定属性的 Python 类（[`Item`](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.Item)）。如上所示，可通过 `.dict` 将其转换为字典。

它包含以下属性：

* `value`：记忆的值（本身是字典）
* `key`：该命名空间中记忆的唯一键
* `namespace`：字符串列表，表示该记忆类型的命名空间
* `created_at`：记忆创建时间
* `updated_at`：记忆更新时间
它包含以下属性：

* `value`：记忆的值
* `key`：该命名空间中记忆的唯一键
* `namespace`：字符串列表，表示该记忆类型的命名空间
* `createdAt`：记忆创建时间
* `updatedAt`：记忆更新时间




### 语义搜索

除了简单检索之外，Store 还支持语义搜索，可根据含义而非精确匹配查找记忆。要启用此功能，请在 Store 中配置一个向量模型：

```python
from langchain.embeddings import init_embeddings

store = InMemoryStore(
    index={
        "embed": init_embeddings("openai:text-embedding-3-small"),  # Embedding provider
        "dims": 1536,                              # Embedding dimensions
        "fields": ["food_preference", "$"]              # Fields to embed
    }
)
```




启用后，您可以使用自然语言查询查找相关记忆：

```python
# Find memories about food preferences
# (This can be done after putting memories into the store)
memories = store.search(
    namespace_for_memory,
    query="What does the user like to eat?",
    limit=3  # Return top 3 matches
)
```




可以通过配置 `fields` 参数，或在存储记忆时指定 `index` 参数，来控制哪些字段会被向量化：

```python
# 仅嵌入特定字段的存储示例
store.put(
    namespace_for_memory,
    str(uuid.uuid4()),
    {
        "food_preference": "I love Italian cuisine",
        "context": "Discussing dinner plans"
    },
    index=["food_preference"]  # Only embed "food_preferences" field
)

# 不进行嵌入的存储（仍可检索，但无法语义搜索）
store.put(
    namespace_for_memory,
    str(uuid.uuid4()),
    {"system_info": "Last updated: 2024-01-01"},
    index=False
)
```




### 在 LangGraph 中使用

准备好上述配置后，我们即可在 LangGraph 中使用 `in_memory_store`。`in_memory_store` 与检查点保存器配合：检查点保存器将状态写入线程（如前所述），`in_memory_store` 允许我们存储可跨线程访问的任意信息。我们在编译图时同时传入检查点保存器和 `in_memory_store`。

```python
from langgraph.checkpoint.memory import InMemorySaver

# We need this because we want to enable threads (conversations)
checkpointer = InMemorySaver()

# ... 在此定义图 ...

# Compile the graph with the checkpointer and store
graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)
```




我们像之前一样使用 `thread_id` 调用图，同时传入 `user_id`，用于将记忆命名空间限定到该用户。

```python
# 调用图
user_id = "1"
config = {"configurable": {"thread_id": "1", "user_id": user_id}}

# 我们先跟 AI 打个招呼
for update in graph.stream(
    {"messages": [{"role": "user", "content": "hi"}]}, config, stream_mode="updates"
):
    print(update)
```




在_任何节点_中，只需将 `store: BaseStore` 与 `config: RunnableConfig` 作为参数传入，即可访问 `in_memory_store` 和 `user_id`。以下展示如何在节点中使用语义搜索查找相关记忆：

```python
def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):

    # Get the user id from the config
    user_id = config["configurable"]["user_id"]

    # Namespace the memory
    namespace = (user_id, "memories")

    # ... Analyze conversation and create a new memory

    # Create a new memory ID
    memory_id = str(uuid.uuid4())

    # We create a new memory
    store.put(namespace, memory_id, {"memory": memory})

```




如上所示，我们还可以在任何节点中访问 Store，并使用 `store.search` 方法获取记忆。记忆以对象列表形式返回，可转换为字典。

```python
memories[-1].dict()
{'value': {'food_preference': 'I like pizza'},
 'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',
 'namespace': ['1', 'memories'],
 'created_at': '2024-10-02T17:22:31.590602+00:00',
 'updated_at': '2024-10-02T17:22:31.590605+00:00'}
```




我们可以获取这些记忆并在模型调用中使用它们。

```python
def call_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):
    # Get the user id from the config
    user_id = config["configurable"]["user_id"]

    # Namespace the memory
    namespace = (user_id, "memories")

    # Search based on the most recent message
    memories = store.search(
        namespace,
        query=state["messages"][-1].content,
        limit=3
    )
    info = "\n".join([d.value["memory"] for d in memories])

    # ... Use memories in the model call
```




如果创建新线程，只要 `user_id` 相同，仍然可以访问同样的记忆。

```python
# 调用图
config = {"configurable": {"thread_id": "2", "user_id": "1"}}

# Let's say hi again
for update in graph.stream(
    {"messages": [{"role": "user", "content": "hi, tell me about my memories"}]}, config, stream_mode="updates"
):
    print(update)
```




当在 LangSmith 上运行（无论本地，如 [Studio](/langsmith/studio)，还是[托管环境](/langsmith/platform-setup)）时，基础 Store 默认可用，编译图时无需显式指定。但若要启用语义搜索，**必须**在 `langgraph.json` 中配置索引设置。例如：

```json
{
    ...
    "store": {
        "index": {
            "embed": "openai:text-embeddings-3-small",
            "dims": 1536,
            "fields": ["$"]
        }
    }
}
```

更多细节和配置选项见[部署指南](/langsmith/semantic-search)。

## 检查点库

在底层，检查点由符合 [`BaseCheckpointSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver) 接口的保存器对象驱动。LangGraph 提供了多个检查点实现，均以可单独安装的库形式提供：

* `langgraph-checkpoint`：检查点保存器的基础接口 ([`BaseCheckpointSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver)) 以及序列化/反序列化接口 ([`SerializerProtocol`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.base.SerializerProtocol))。包含用于实验的内存检查点实现 ([`InMemorySaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.memory.InMemorySaver))。LangGraph 默认包含该库。
* `langgraph-checkpoint-sqlite`：使用 SQLite 数据库的检查点实现 ([`SqliteSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.sqlite.SqliteSaver) / [`AsyncSqliteSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver))，适合实验和本地工作流。需单独安装。
* `langgraph-checkpoint-postgres`：使用 Postgres 数据库的高级检查点实现 ([`PostgresSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.postgres.PostgresSaver) / [`AsyncPostgresSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.postgres.aio.AsyncPostgresSaver))，LangSmith 亦在使用，适合生产环境。需单独安装。




### 检查点接口

每个检查点保存器都遵循 [`BaseCheckpointSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver) 接口，并实现以下方法：

* `.put` —— 保存带有配置和元数据的检查点。
* `.put_writes` —— 保存与检查点关联的中间写入（即[待写入数据](#pending-writes)）。
* `.get_tuple` —— 根据给定配置（`thread_id` 和 `checkpoint_id`）获取检查点元组，用于在 `graph.get_state()` 中生成 `StateSnapshot`。
* `.list` —— 列出与给定配置及筛选条件匹配的检查点，用于在 `graph.get_state_history()` 中生成状态历史。

如果在异步图执行（例如通过 `.ainvoke`、`.astream`、`.abatch`）中使用检查点，则会使用以上方法的异步版本（`.aput`、`.aput_writes`、`.aget_tuple`、`.alist`）。

<Note>
若要异步运行图，可以使用 [`InMemorySaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.memory.InMemorySaver)，或使用 Sqlite/Postgres 检查点的异步版本 —— [`AsyncSqliteSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver) / [`AsyncPostgresSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.postgres.aio.AsyncPostgresSaver)。
</Note>




### 序列化器

检查点保存图状态时，需要对状态中的通道值进行序列化，这通过序列化器对象完成。

`langgraph_checkpoint` 定义了实现序列化器的 [protocol](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.base.SerializerProtocol)，并提供默认实现 ([`JsonPlusSerializer`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer))，可处理包括 LangChain/LangGraph 原语、日期时间、枚举等在内的多种类型。

#### 使用 `pickle` 序列化

默认的 [`JsonPlusSerializer`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer) 底层使用 ormsgpack 和 JSON，对所有对象类型并不适用。

如果希望对当前 msgpack 编码器不支持的对象（如 Pandas DataFrame）回退到 pickle，可以在 [`JsonPlusSerializer`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer) 中使用 `pickle_fallback` 参数：

```python
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer

# ... 在此定义图 ...
graph.compile(
    checkpointer=InMemorySaver(serde=JsonPlusSerializer(pickle_fallback=True))
)
```

#### 加密

检查点保存器可选择对所有持久化状态进行加密。要启用加密，可在任意 [`BaseCheckpointSaver`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver) 实现的 `serde` 参数中传入 [`EncryptedSerializer`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.encrypted.EncryptedSerializer) 实例。创建加密序列化器的最简方式是使用 [`from_pycryptodome_aes`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.encrypted.EncryptedSerializer.from_pycryptodome_aes)，它会从 `LANGGRAPH_AES_KEY` 环境变量读取 AES 密钥（或接受 `key` 参数）：

```python
import sqlite3

from langgraph.checkpoint.serde.encrypted import EncryptedSerializer
from langgraph.checkpoint.sqlite import SqliteSaver

serde = EncryptedSerializer.from_pycryptodome_aes()  # reads LANGGRAPH_AES_KEY
checkpointer = SqliteSaver(sqlite3.connect("checkpoint.db"), serde=serde)
```

```python
from langgraph.checkpoint.serde.encrypted import EncryptedSerializer
from langgraph.checkpoint.postgres import PostgresSaver

serde = EncryptedSerializer.from_pycryptodome_aes()
checkpointer = PostgresSaver.from_conn_string("postgresql://...", serde=serde)
checkpointer.setup()
```

在 LangSmith 上运行时，只要存在 `LANGGRAPH_AES_KEY`，就会自动启用加密，因此只需提供该环境变量。也可以通过实现 [`CipherProtocol`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.base.CipherProtocol) 并传递给 [`EncryptedSerializer`](https://reference.langchain.com/python/langgraph/checkpoints/#langgraph.checkpoint.serde.encrypted.EncryptedSerializer) 来使用其他加密方案。

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\langgraph\persistence.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
