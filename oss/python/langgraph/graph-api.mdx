---
title: Graph API 概述
sidebarTitle: Graph API
---



## 图

LangGraph 的核心是将代理工作流建模为图。您使用三个关键组件定义代理的行为：

1. [`State`](#state)：表示应用程序当前快照的共享数据结构。它可以是任何数据类型，但通常使用共享状态模式定义。

2. [`Nodes`](#nodes)：编码代理逻辑的函数。它们接收当前状态作为输入，执行一些计算或副作用，并返回更新的状态。

3. [`Edges`](#edges)：根据当前状态确定接下来执行哪个 `Node` 的函数。它们可以是条件分支或固定转换。

通过组合 `Nodes` 和 `Edges`，您可以创建随时间演变的复杂循环工作流。然而，真正的力量来自 LangGraph 如何管理该状态。

需要强调的是：`Nodes` 和 `Edges` 只不过是函数——它们可以包含 LLM 或只是普通的代码。

简而言之：_节点执行工作，边告诉下一步做什么_。

LangGraph 的底层图算法使用[消息传递](https://en.wikipedia.org/wiki/Message_passing)来定义通用程序。当节点完成其操作时，它沿着一条或多条边向其他节点发送消息。然后这些接收节点执行其函数，将结果消息传递给下一组节点，过程继续。受 Google 的 [Pregel](https://research.google/pubs/pregel-a-system-for-large-scale-graph-processing/) 系统启发，程序以离散的"超级步骤"进行。

超级步骤可以视为图节点的一次迭代。并行运行的节点属于同一超级步骤，而顺序运行的节点属于不同的超级步骤。在图执行开始时，所有节点都处于 `inactive` 状态。当节点在其任何传入边（或"通道"）上接收到新消息（状态）时，它变为 `active`。然后活动节点运行其函数并响应更新。在每个超级步骤结束时，没有传入消息的节点通过将自己标记为 `inactive` 来投票 `halt`。当所有节点都是 `inactive` 且没有消息在传输中时，图执行终止。

### StateGraph

[`StateGraph`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.StateGraph) 类是使用的主要图类。它由用户定义的 `State` 对象参数化。

### 编译您的图

要构建图，您首先定义[状态](#state)，然后添加[节点](#nodes)和[边](#edges)，然后编译它。编译图到底是什么，为什么需要它？

编译是一个相当简单的步骤。它提供对图结构的一些基本检查（没有孤立节点等）。这也是您可以指定运行时参数（如[检查点](/oss/python/langgraph/persistence)和断点）的地方。您只需调用 `.compile` 方法来编译图：

```python
graph = graph_builder.compile(...)
```





<Warning>
    您**必须**在使用图之前编译它。
</Warning>

## 状态

定义图时，您要做的第一件事是定义图的 `State`。`State` 由[图的模式](#schema)以及指定如何将更新应用到状态的[`reducer` 函数](#reducers)组成。`State` 的模式将是图中所有 `Nodes` 和 `Edges` 的输入模式，可以是 `TypedDict` 或 `Pydantic` 模型。所有 `Nodes` 都会发出对 `State` 的更新，然后使用指定的 `reducer` 函数应用这些更新。




### 模式

指定图模式的主要文档方法是使用 [`TypedDict`](https://docs.python.org/3/library/typing.html#typing.TypedDict)。如果您想在状态中提供默认值，请使用 [`dataclass`](https://docs.python.org/3/library/dataclasses.html)。如果您想要递归数据验证，我们也支持使用 Pydantic [`BaseModel`](/oss/python/langgraph/use-graph-api#use-pydantic-models-for-graph-state) 作为图状态（但请注意，Pydantic 的性能不如 `TypedDict` 或 `dataclass`）。

默认情况下，图将具有相同的输入和输出模式。如果您想更改此设置，也可以直接指定显式的输入和输出模式。当您有很多键，并且某些键明确用于输入而其他键用于输出时，这很有用。有关更多信息，请参阅[指南](/oss/python/langgraph/use-graph-api#define-input-and-output-schemas)。




#### 多个模式

通常，所有图节点都与单个模式通信。这意味着它们将读取和写入相同的状态通道。但是，在某些情况下，我们希望对此有更多控制：

- 内部节点可以传递图中输入/输出不需要的信息。
- 我们可能还想为图使用不同的输入/输出模式。例如，输出可能只包含单个相关的输出键。

可以让节点写入图内的私有状态通道以进行内部节点通信。我们可以简单地定义一个私有模式 `PrivateState`。

也可以为图定义显式的输入和输出模式。在这些情况下，我们定义一个包含与图操作相关的_所有_键的"内部"模式。但是，我们还定义 `input` 和 `output` 模式，它们是"内部"模式的子集，以约束图的输入和输出。有关更多详细信息，请参阅[此指南](/oss/python/langgraph/graph-api#define-input-and-output-schemas)。

让我们看一个示例：

```python
class InputState(TypedDict):
    user_input: str

class OutputState(TypedDict):
    graph_output: str

class OverallState(TypedDict):
    foo: str
    user_input: str
    graph_output: str

class PrivateState(TypedDict):
    bar: str

def node_1(state: InputState) -> OverallState:
    # 写入 OverallState
    return {"foo": state["user_input"] + " name"}

def node_2(state: OverallState) -> PrivateState:
    # 从 OverallState 读取，写入 PrivateState
    return {"bar": state["foo"] + " is"}

def node_3(state: PrivateState) -> OutputState:
    # 从 PrivateState 读取，写入 OutputState
    return {"graph_output": state["bar"] + " Lance"}

builder = StateGraph(OverallState,input_schema=InputState,output_schema=OutputState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)
builder.add_edge(START, "node_1")
builder.add_edge("node_1", "node_2")
builder.add_edge("node_2", "node_3")
builder.add_edge("node_3", END)

graph = builder.compile()
graph.invoke({"user_input":"My"})
# {'graph_output': 'My name is Lance'}
```





这里有两个微妙而重要的点需要注意：

1. 我们将 `state: InputState` 作为输入模式传递给 `node_1`。但是，我们写入 `foo`，这是 `OverallState` 中的一个通道。我们如何写入输入模式中不包含的状态通道？这是因为节点_可以写入图状态中的任何状态通道_。图状态是在初始化时定义的状态通道的并集，包括 `OverallState` 以及过滤器 `InputState` 和 `OutputState`。

2. 我们使用以下方式初始化图：

    ```python
    StateGraph(
        OverallState,
        input_schema=InputState,
        output_schema=OutputState
    )
    ```

    那么，我们如何在 `node_2` 中写入 `PrivateState`？如果它没有在 `StateGraph` 初始化中传递，图如何获得对此模式的访问权限？

    我们可以这样做，因为只要状态模式定义存在，`_nodes` 也可以声明额外的状态 `channels_`。在这种情况下，`PrivateState` 模式已定义，因此我们可以在图中添加 `bar` 作为新状态通道并写入它。




### Reducers

Reducers 是理解节点更新如何应用到 `State` 的关键。`State` 中的每个键都有自己独立的 reducer 函数。如果没有明确指定 reducer 函数，则假定对该键的所有更新都应该覆盖它。有几种不同类型的 reducers，从默认类型的 reducer 开始：

#### 默认 Reducer

这两个示例展示了如何使用默认 reducer：

```python Example A
from typing_extensions import TypedDict

class State(TypedDict):
    foo: int
    bar: list[str]
```





在此示例中，没有为任何键指定 reducer 函数。假设图的输入是：

`{"foo": 1, "bar": ["hi"]}`。然后假设第一个 `Node` 返回 `{"foo": 2}`。这被视为对状态的更新。请注意，`Node` 不需要返回整个 `State` 模式——只需要一个更新。应用此更新后，`State` 将是 `{"foo": 2, "bar": ["hi"]}`。如果第二个节点返回 `{"bar": ["bye"]}`，那么 `State` 将是 `{"foo": 2, "bar": ["bye"]}`




```python Example B
from typing import Annotated
from typing_extensions import TypedDict
from operator import add

class State(TypedDict):
    foo: int
    bar: Annotated[list[str], add]
```

在此示例中，我们使用 `Annotated` 类型为第二个键（`bar`）指定 reducer 函数（`operator.add`）。请注意，第一个键保持不变。假设图的输入是 `{"foo": 1, "bar": ["hi"]}`。然后假设第一个 `Node` 返回 `{"foo": 2}`。这被视为对状态的更新。请注意，`Node` 不需要返回整个 `State` 模式——只需要一个更新。应用此更新后，`State` 将是 `{"foo": 2, "bar": ["hi"]}`。如果第二个节点返回 `{"bar": ["bye"]}`，那么 `State` 将是 `{"foo": 2, "bar": ["hi", "bye"]}`。请注意，这里通过将两个列表相加来更新 `bar` 键。




#### Overwrite
<Tip>
在某些情况下，您可能希望绕过 reducer 并直接覆盖状态值。LangGraph 为此提供了 [`Overwrite`](https://reference.langchain.com/python/langgraph/types/) 类型。[在此了解如何使用 `Overwrite`](/oss/python/langgraph/use-graph-api#bypass-reducers-with-overwrite)。
</Tip>


### 在图状态中使用消息

#### 为什么使用消息？

大多数现代 LLM 提供商都有一个接受消息列表作为输入的聊天模型接口。LangChain 的[聊天模型接口](/oss/python/langchain/models)特别接受消息对象列表作为输入。这些消息有多种形式，例如 [`HumanMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.HumanMessage)（用户输入）或 [`AIMessage`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.AIMessage)（LLM 响应）。

要了解更多关于消息对象的信息，请参阅[消息概念指南](/oss/python/langchain/messages)。

#### 在图中使用消息

在许多情况下，将先前的对话历史作为消息列表存储在图状态中很有帮助。为此，我们可以向图状态添加一个键（通道），该键存储 `Message` 对象列表，并使用 reducer 函数对其进行注释（请参见下面的示例中的 `messages` 键）。reducer 函数对于告诉图如何用每次状态更新更新状态中的 `Message` 对象列表至关重要（例如，当节点发送更新时）。如果您不指定 reducer，每次状态更新都会用最近提供的值覆盖消息列表。如果您只想将消息追加到现有列表，可以使用 `operator.add` 作为 reducer。

但是，您可能还想手动更新图状态中的消息（例如，人机协作）。如果您使用 `operator.add`，您发送到图的手动状态更新将被追加到现有消息列表中，而不是更新现有消息。为了避免这种情况，您需要一个可以跟踪消息 ID 并在更新时覆盖现有消息的 reducer。为此，您可以使用预构建的 [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) 函数。对于全新的消息，它将简单地追加到现有列表，但它也会正确处理现有消息的更新。




#### 序列化

除了跟踪消息 ID 之外，[`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) 函数还会尝试在 `messages` 通道上收到状态更新时，将消息反序列化为 LangChain `Message` 对象。

有关 LangChain 序列化/反序列化的更多信息，请参阅[此处](https://python.langchain.com/docs/how_to/serialization/)。这允许以以下格式发送图输入/状态更新：

```python
# 支持此格式
{"messages": [HumanMessage(content="message")]}

# 也支持此格式
{"messages": [{"type": "human", "content": "message"}]}
```

由于使用 [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) 时状态更新总是反序列化为 LangChain `Messages`，您应该使用点表示法访问消息属性，如 `state["messages"][-1].content`。

下面是一个使用 [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) 作为 reducer 函数的图示例。

```python
from langchain.messages import AnyMessage
from langgraph.graph.message import add_messages
from typing import Annotated
from typing_extensions import TypedDict

class GraphState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]
```





#### MessagesState

由于在状态中拥有消息列表非常常见，因此存在一个名为 `MessagesState` 的预构建状态，这使得使用消息变得容易。`MessagesState` 定义为具有单个 `messages` 键，该键是 `AnyMessage` 对象列表，并使用 [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) reducer。通常，要跟踪的状态不仅仅是消息，因此我们看到人们子类化此状态并添加更多字段，例如：

```python
from langgraph.graph import MessagesState

class State(MessagesState):
    documents: list[str]
```



## 节点

在 LangGraph 中，节点是接受以下参数的 Python 函数（同步或异步）：

1. `state` – 图的[状态](#state)
2. `config` – 包含配置信息（如 `thread_id`）和跟踪信息（如 `tags`）的 [`RunnableConfig`](https://reference.langchain.com/python/langchain_core/runnables/#langchain_core.runnables.RunnableConfig) 对象
3. `runtime` – 包含[运行时 `context`](#runtime-context) 和其他信息（如 `store` 和 `stream_writer`）的 `Runtime` 对象

类似于 `NetworkX`，您使用 [`add_node`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.StateGraph.add_node) 方法将这些节点添加到图中：

```python
from dataclasses import dataclass
from typing_extensions import TypedDict

from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph
from langgraph.runtime import Runtime

class State(TypedDict):
    input: str
    results: str

@dataclass
class Context:
    user_id: str

builder = StateGraph(State)

def plain_node(state: State):
    return state

def node_with_runtime(state: State, runtime: Runtime[Context]):
    print("In node: ", runtime.context.user_id)
    return {"results": f"Hello, {state['input']}!"}

def node_with_config(state: State, config: RunnableConfig):
    print("In node with thread_id: ", config["configurable"]["thread_id"])
    return {"results": f"Hello, {state['input']}!"}


builder.add_node("plain_node", plain_node)
builder.add_node("node_with_runtime", node_with_runtime)
builder.add_node("node_with_config", node_with_config)
...
```





在幕后，函数被转换为 [`RunnableLambda`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html)，它为您的函数添加批处理和异步支持，以及本机跟踪和调试。

如果您在不指定名称的情况下将节点添加到图中，它将获得一个等于函数名称的默认名称。

```python
builder.add_node(my_node)
# 然后您可以通过将其引用为 `"my_node"` 来创建到此节点的边
```





### `START` 节点

[`START`](https://reference.langchain.com/python/langgraph/constants/#langgraph.constants.START) 节点是一个特殊节点，表示将用户输入发送到图的节点。引用此节点的主要目的是确定应该首先调用哪些节点。

```python
from langgraph.graph import START

graph.add_edge(START, "node_a")
```





### `END` 节点

`END` 节点是一个特殊节点，表示终端节点。当您想表示哪些边在完成后没有操作时，会引用此节点。

```python
from langgraph.graph import END

graph.add_edge("node_a", END)
```





### 节点缓存

LangGraph 支持基于节点输入的任务/节点缓存。要使用缓存：

- 在编译图时（或指定入口点时）指定缓存
- 为节点指定缓存策略。每个缓存策略支持：
  - `key_func` 用于基于节点输入生成缓存键，默认为使用 pickle 的输入 `hash`。
  - `ttl`，缓存的生存时间（以秒为单位）。如果未指定，缓存将永不过期。

例如：

```python
import time
from typing_extensions import TypedDict
from langgraph.graph import StateGraph
from langgraph.cache.memory import InMemoryCache
from langgraph.types import CachePolicy


class State(TypedDict):
    x: int
    result: int


builder = StateGraph(State)


def expensive_node(state: State) -> dict[str, int]:
    # 昂贵的计算
    time.sleep(2)
    return {"result": state["x"] * 2}


builder.add_node("expensive_node", expensive_node, cache_policy=CachePolicy(ttl=3))
builder.set_entry_point("expensive_node")
builder.set_finish_point("expensive_node")

graph = builder.compile(cache=InMemoryCache())

print(graph.invoke({"x": 5}, stream_mode='updates'))    # [!code highlight]
# [{'expensive_node': {'result': 10}}]
print(graph.invoke({"x": 5}, stream_mode='updates'))    # [!code highlight]
# [{'expensive_node': {'result': 10}, '__metadata__': {'cached': True}}]
```

1. 第一次运行需要两秒钟（由于模拟的昂贵计算）。
2. 第二次运行利用缓存并快速返回。




## 边

边定义逻辑如何路由以及图如何决定停止。这是代理如何工作以及不同节点如何相互通信的重要组成部分。有几种关键类型的边：

- 普通边：直接从一個节点到下一个节点。
- 条件边：调用函数以确定接下来转到哪个节点。
- 入口点：当用户输入到达时首先调用哪个节点。
- 条件入口点：调用函数以确定当用户输入到达时首先调用哪个节点。

一个节点可以有多个传出边。如果一个节点有多个传出边，**所有**这些目标节点将作为下一个超级步骤的一部分并行执行。

### 普通边

如果您**总是**想从节点 A 转到节点 B，可以直接使用 [`add_edge`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.StateGraph.add_edge) 方法。

```python
graph.add_edge("node_a", "node_b")
```





### 条件边

如果您想**可选地**路由到一个或多个边（或可选地终止），可以使用 [`add_conditional_edges`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.StateGraph.add_conditional_edges) 方法。此方法接受节点名称和在该节点执行后调用的"路由函数"：

```python
graph.add_conditional_edges("node_a", routing_function)
```

类似于节点，`routing_function` 接受图的当前 `state` 并返回值。

默认情况下，返回值 `routing_function` 用作要发送状态的节点（或节点列表）的名称。所有这些节点将作为下一个超级步骤的一部分并行运行。

您可以可选地提供一个字典，将 `routing_function` 的输出映射到下一个节点的名称。

```python
graph.add_conditional_edges("node_a", routing_function, {True: "node_b", False: "node_c"})
```





<Tip>

如果您想在单个函数中组合状态更新和路由，请使用 [`Command`](#command) 而不是条件边。

</Tip>

### 入口点

入口点是图启动时运行的第一个节点。您可以使用从虚拟 [`START`](https://reference.langchain.com/python/langgraph/constants/#langgraph.constants.START) 节点到要执行的第一个节点的 [`add_edge`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.StateGraph.add_edge) 方法来指定图的入口位置。

```python
from langgraph.graph import START

graph.add_edge(START, "node_a")
```





### 条件入口点

条件入口点允许您根据自定义逻辑从不同的节点开始。您可以使用虚拟 [`START`](https://reference.langchain.com/python/langgraph/constants/#langgraph.constants.START) 节点的 [`add_conditional_edges`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.state.StateGraph.add_conditional_edges) 来实现此目的。

```python
from langgraph.graph import START

graph.add_conditional_edges(START, routing_function)
```

您可以可选地提供一个字典，将 `routing_function` 的输出映射到下一个节点的名称。

```python
graph.add_conditional_edges(START, routing_function, {True: "node_b", False: "node_c"})
```





## `Send`

默认情况下，`Nodes` 和 `Edges` 是预先定义的，并在相同的共享状态上操作。但是，在某些情况下，确切的边可能事先未知，和/或您可能希望同时存在不同版本的 `State`。一个常见的例子是[map-reduce](/oss/python/langgraph/graph-api#map-reduce-and-the-send-api) 设计模式。在这种设计模式中，第一个节点可能生成对象列表，您可能希望将某个其他节点应用于所有这些对象。对象的数量可能事先未知（意味着边的数量可能未知），并且下游 `Node` 的输入 `State` 应该不同（每个生成的对象一个）。

为了支持这种设计模式，LangGraph 支持从条件边返回 [`Send`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Send) 对象。`Send` 接受两个参数：第一个是节点名称，第二个是传递给该节点的状态。

```python
def continue_to_jokes(state: OverallState):
    return [Send("generate_joke", {"subject": s}) for s in state['subjects']]

graph.add_conditional_edges("node_a", continue_to_jokes)
```





## `Command`

组合控制流（边）和状态更新（节点）可能很有用。例如，您可能希望在**同一个**节点中**同时**执行状态更新**并**决定下一步转到哪个节点。LangGraph 提供了一种通过从节点函数返回 [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 对象来实现此目的的方法：

```python
def my_node(state: State) -> Command[Literal["my_other_node"]]:
    return Command(
        # 状态更新
        update={"foo": "bar"},
        # 控制流
        goto="my_other_node"
    )
```

使用 [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 您还可以实现动态控制流行为（与[条件边](#conditional-edges)相同）：

```python
def my_node(state: State) -> Command[Literal["my_other_node"]]:
    if state["foo"] == "bar":
        return Command(update={"foo": "baz"}, goto="my_other_node")
```





<Note>

在节点函数中返回 [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 时，必须添加返回类型注释，其中包含节点路由到的节点名称列表，例如 `Command[Literal["my_other_node"]]`。这对于图渲染是必要的，并告诉 LangGraph `my_node` 可以导航到 `my_other_node`。

</Note>

查看此[操作指南](/oss/python/langgraph/use-graph-api#combine-control-flow-and-state-updates-with-command)以获取如何使用 [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 的端到端示例。

### 我应该何时使用 Command 而不是条件边？

- 当您需要**同时**更新图状态**并**路由到不同节点时，请使用 [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command)。例如，在实现[多代理交接](/oss/python/langchain/multi-agent#handoffs)时，路由到不同代理并向该代理传递一些信息很重要。
- 使用[条件边](#conditional-edges)在节点之间进行条件路由，而不更新状态。

### 导航到父图中的节点

如果您使用[子图](/oss/python/langgraph/use-subgraphs)，您可能希望从子图内的节点导航到不同的子图（即父图中的不同节点）。为此，您可以在 [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 中指定 `graph=Command.PARENT`：

```python
def my_node(state: State) -> Command[Literal["other_subgraph"]]:
    return Command(
        update={"foo": "bar"},
        goto="other_subgraph",  # 其中 `other_subgraph` 是父图中的节点
        graph=Command.PARENT
    )
```

<Note>

将 `graph` 设置为 `Command.PARENT` 将导航到最近的父图。

当您从子图节点向父图节点发送更新时，对于父图和子图[状态模式](#schema)共享的键，您**必须**在父图状态中为您正在更新的键定义[reducer](#reducers)。请参阅此[示例](/oss/python/langgraph/use-graph-api#navigate-to-a-node-in-a-parent-graph)。

</Note>







这在实现[多代理交接](/oss/python/langchain/multi-agent#handoffs)时特别有用。

查看[此指南](/oss/python/langgraph/use-graph-api#navigate-to-a-node-in-a-parent-graph)了解详细信息。

### 在工具内使用

一个常见的用例是从工具内部更新图状态。例如，在客户支持应用程序中，您可能希望在对话开始时根据客户的帐号或 ID 查找客户信息。

请参阅[此指南](/oss/python/langgraph/use-graph-api#use-inside-tools)了解详细信息。

### 人机协作

[`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 是人机协作工作流的重要组成部分：使用 `interrupt()` 收集用户输入时，[`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) 用于提供输入并通过 `Command(resume="User input")` 恢复执行。查看[此概念指南](/oss/python/langgraph/interrupts)了解更多信息。




## 图迁移

LangGraph 可以轻松处理图定义（节点、边和状态）的迁移，即使在使用检查点跟踪状态时也是如此。

- 对于图末尾的线程（即未中断），您可以更改图的整个拓扑（即所有节点和边，删除、添加、重命名等）
- 对于当前中断的线程，我们支持除重命名/删除节点之外的所有拓扑更改（因为该线程现在可能即将进入一个不再存在的节点）——如果这是一个阻碍，请联系我们，我们可以优先解决。
- 对于修改状态，我们在添加和删除键方面具有完全的向后和向前兼容性
- 重命名的状态键会在现有线程中丢失其保存的状态
- 以不兼容方式更改类型的状态键可能会在具有更改前状态的线程中导致问题——如果这是一个阻碍，请联系我们，我们可以优先解决。

## 运行时上下文

创建图时，您可以为传递给节点的运行时上下文指定 `context_schema`。这对于向节点传递不属于图状态的信息很有用。例如，您可能希望传递依赖项，例如模型名称或数据库连接。





```python
@dataclass
class ContextSchema:
    llm_provider: str = "openai"

graph = StateGraph(State, context_schema=ContextSchema)
```

然后，您可以使用 `invoke` 方法的 `context` 参数将此上下文传递到图中。

```python
graph.invoke(inputs, context={"llm_provider": "anthropic"})
```




然后，您可以在节点或条件边内访问和使用此上下文：

```python
from langgraph.runtime import Runtime

def node_a(state: State, runtime: Runtime[ContextSchema]):
    llm = get_llm(runtime.context.llm_provider)
    # ...
```




有关配置的完整说明，请参阅[此指南](/oss/python/langgraph/use-graph-api#add-runtime-configuration)。



### 递归限制

递归限制设置图在单次执行期间可以执行的[超级步骤](#graphs)的最大数量。一旦达到限制，LangGraph 将引发 `GraphRecursionError`。默认情况下，此值设置为 25 步。递归限制可以在运行时在任何图上设置，并通过配置字典传递给 `invoke`/`stream`。重要的是，`recursion_limit` 是一个独立的 `config` 键，不应像所有其他用户定义的配置一样传递到 `configurable` 键内。请参阅下面的示例：

```python
graph.invoke(inputs, config={"recursion_limit": 5}, context={"llm": "anthropic"})
```

阅读[此操作指南](/oss/python/langgraph/graph-api#impose-a-recursion-limit)以了解更多关于递归限制如何工作的信息。




### 访问和处理递归计数器

当前步骤计数器可在任何节点内的 `config["metadata"]["langgraph_step"]` 中访问，允许在达到递归限制之前主动处理递归。这使您能够在图逻辑中实现优雅降级策略。




#### 工作原理

步骤计数器存储在 `config["metadata"]["langgraph_step"]` 中。递归限制检查遵循逻辑：`step > stop`，其中 `stop = step + recursion_limit + 1`。当超过限制时，LangGraph 会引发 `GraphRecursionError`。





#### 访问当前步骤计数器

您可以在任何节点内访问当前步骤计数器以监控执行进度。

```python
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph

def my_node(state: dict, config: RunnableConfig) -> dict:
    current_step = config["metadata"]["langgraph_step"]
    print(f"Currently on step: {current_step}")
    return state
```





#### 主动递归处理

您可以检查步骤计数器并在达到限制之前主动路由到不同的节点。这允许在图内进行优雅降级。

```python
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END

def reasoning_node(state: dict, config: RunnableConfig) -> dict:
    current_step = config["metadata"]["langgraph_step"]
    recursion_limit = config["recursion_limit"]  # 始终存在，默认为 25

    # 检查是否接近限制（例如，80% 阈值）
    if current_step >= recursion_limit * 0.8:
        return {
            **state,
            "route_to": "fallback",
            "reason": "Approaching recursion limit"
        }

    # 正常处理
    return {"messages": state["messages"] + ["thinking..."]}

def fallback_node(state: dict, config: RunnableConfig) -> dict:
    """处理接近递归限制的情况"""
    return {
        **state,
        "messages": state["messages"] + ["Reached complexity limit, providing best effort answer"]
    }

def route_based_on_state(state: dict) -> str:
    if state.get("route_to") == "fallback":
        return "fallback"
    elif state.get("done"):
        return END
    return "reasoning"

# 构建图
graph = StateGraph(dict)
graph.add_node("reasoning", reasoning_node)
graph.add_node("fallback", fallback_node)
graph.add_conditional_edges("reasoning", route_based_on_state)
graph.add_edge("fallback", END)
graph.set_entry_point("reasoning")

app = graph.compile()
```





#### 主动与被动方法

处理递归限制有两种主要方法：主动（在图内监控）和被动（在外部捕获错误）。

```python
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.errors import GraphRecursionError

# 主动方法（推荐）
def agent_with_monitoring(state: dict, config: RunnableConfig) -> dict:
    """主动监控和处理图内的递归"""
    current_step = config["metadata"]["langgraph_step"]
    recursion_limit = config["recursion_limit"]

    # 早期检测 - 路由到内部处理
    if current_step >= recursion_limit - 2:  # 限制前 2 步
        return {
            **state,
            "status": "recursion_limit_approaching",
            "final_answer": "Reached iteration limit, returning partial result"
        }

    # 正常处理
    return {"messages": state["messages"] + [f"Step {current_step}"]}

# 被动方法（后备）
try:
    result = graph.invoke(initial_state, {"recursion_limit": 10})
except GraphRecursionError as e:
    # 在图执行失败后外部处理
    result = fallback_handler(initial_state)
```





这些方法之间的主要区别是：

| 方法 | 检测 | 处理 | 控制流 |
|----------|-----------|----------|--------------|
| 主动（使用 `langgraph_step`） | 达到限制之前 | 通过条件路由在图内 | 图继续到完成节点 |
| 被动（捕获 `GraphRecursionError`） | 超过限制之后 | 在 try/catch 中在图外 | 图执行终止 |

**主动方法的优势：**

- 在图内优雅降级
- 可以在检查点中保存中间状态
- 部分结果带来更好的用户体验
- 图正常完成（无异常）

**被动方法的优势：**

- 实现更简单
- 无需修改图逻辑
- 集中错误处理

#### 其他可用的元数据

除了 `langgraph_step`，以下元数据也可在 `config["metadata"]` 中使用：

```python
def inspect_metadata(state: dict, config: RunnableConfig) -> dict:
    metadata = config["metadata"]

    print(f"Step: {metadata['langgraph_step']}")
    print(f"Node: {metadata['langgraph_node']}")
    print(f"Triggers: {metadata['langgraph_triggers']}")
    print(f"Path: {metadata['langgraph_path']}")
    print(f"Checkpoint NS: {metadata['langgraph_checkpoint_ns']}")

    return state
```





## 可视化

能够可视化图通常很有用，特别是当它们变得更复杂时。LangGraph 提供了几种内置的可视化图的方法。有关更多信息，请参阅[此操作指南](/oss/python/langgraph/use-graph-api#visualize-your-graph)。

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\langgraph\graph-api.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
