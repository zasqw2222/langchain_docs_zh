---
title: å·¥å…·
---



è®¸å¤š AI åº”ç”¨é€šè¿‡è‡ªç„¶è¯­è¨€ä¸ç”¨æˆ·äº¤äº’ã€‚ä½†æ˜¯ï¼ŒæŸäº›ç”¨ä¾‹è¦æ±‚æ¨¡å‹ä½¿ç”¨ç»“æ„åŒ–è¾“å…¥ç›´æ¥ä¸å¤–éƒ¨ç³»ç»Ÿï¼ˆå¦‚ APIã€æ•°æ®åº“æˆ–æ–‡ä»¶ç³»ç»Ÿï¼‰äº¤äº’ã€‚

å·¥å…·æ˜¯[ä»£ç†](/oss/python/langchain/agents)è°ƒç”¨ä»¥æ‰§è¡Œæ“ä½œçš„ç»„ä»¶ã€‚å®ƒä»¬é€šè¿‡è®©æ¨¡å‹é€šè¿‡æ˜ç¡®å®šä¹‰çš„è¾“å…¥å’Œè¾“å‡ºä¸ä¸–ç•Œäº¤äº’æ¥æ‰©å±•æ¨¡å‹èƒ½åŠ›ã€‚å·¥å…·å°è£…äº†ä¸€ä¸ªå¯è°ƒç”¨å‡½æ•°åŠå…¶è¾“å…¥æ¨¡å¼ã€‚è¿™äº›å¯ä»¥ä¼ é€’ç»™å…¼å®¹çš„[èŠå¤©æ¨¡å‹](/oss/python/langchain/models)ï¼Œå…è®¸æ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ä»¥åŠä½¿ç”¨ä»€ä¹ˆå‚æ•°ã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œå·¥å…·è°ƒç”¨ä½¿æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆç¬¦åˆæŒ‡å®šè¾“å…¥æ¨¡å¼çš„è¯·æ±‚ã€‚

<Note>
**æœåŠ¡å™¨ç«¯å·¥å…·ä½¿ç”¨**

æŸäº›èŠå¤©æ¨¡å‹ï¼ˆä¾‹å¦‚ [OpenAI](/oss/python/integrations/chat/openai)ã€[Anthropic](/oss/python/integrations/chat/anthropic) å’Œ [Gemini](/oss/python/integrations/chat/google_generative_ai)ï¼‰å…·æœ‰[å†…ç½®å·¥å…·](/oss/python/langchain/models#server-side-tool-use)ï¼Œè¿™äº›å·¥å…·åœ¨æœåŠ¡å™¨ç«¯æ‰§è¡Œï¼Œä¾‹å¦‚ç½‘ç»œæœç´¢å’Œä»£ç è§£é‡Šå™¨ã€‚è¯·å‚é˜…[æä¾›è€…æ¦‚è¿°](/oss/python/integrations/providers/overview)ä»¥äº†è§£å¦‚ä½•ä½¿ç”¨æ‚¨çš„ç‰¹å®šèŠå¤©æ¨¡å‹è®¿é—®è¿™äº›å·¥å…·ã€‚
</Note>

## åˆ›å»ºå·¥å…·

### åŸºæœ¬å·¥å…·å®šä¹‰

åˆ›å»ºå·¥å…·çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨ [`@tool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool) è£…é¥°å™¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå‡½æ•°çš„æ–‡æ¡£å­—ç¬¦ä¸²æˆä¸ºå·¥å…·çš„æè¿°ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£ä½•æ—¶ä½¿ç”¨å®ƒï¼š

```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """Search the customer database for records matching the query.

    Args:
        query: Search terms to look for
        limit: Maximum number of results to return
    """
    return f"Found {limit} results for '{query}'"
```

ç±»å‹æç¤ºæ˜¯**å¿…éœ€çš„**ï¼Œå› ä¸ºå®ƒä»¬å®šä¹‰äº†å·¥å…·çš„è¾“å…¥æ¨¡å¼ã€‚æ–‡æ¡£å­—ç¬¦ä¸²åº”è¯¥ä¿¡æ¯ä¸°å¯Œä¸”ç®€æ´ï¼Œä»¥å¸®åŠ©æ¨¡å‹ç†è§£å·¥å…·çš„ç”¨é€”ã€‚




### è‡ªå®šä¹‰å·¥å…·å±æ€§

#### è‡ªå®šä¹‰å·¥å…·åç§°

é»˜è®¤æƒ…å†µä¸‹ï¼Œå·¥å…·åç§°æ¥è‡ªå‡½æ•°åç§°ã€‚å½“æ‚¨éœ€è¦æ›´å…·æè¿°æ€§çš„åç§°æ—¶ï¼Œå¯ä»¥è¦†ç›–å®ƒï¼š

```python
@tool("web_search")  # è‡ªå®šä¹‰åç§°
def search(query: str) -> str:
    """Search the web for information."""
    return f"Results for: {query}"

print(search.name)  # web_search
```

#### è‡ªå®šä¹‰å·¥å…·æè¿°

è¦†ç›–è‡ªåŠ¨ç”Ÿæˆçš„å·¥å…·æè¿°ï¼Œä»¥ä¾¿ä¸ºæ¨¡å‹æä¾›æ›´æ¸…æ™°çš„æŒ‡å¯¼ï¼š

```python
@tool("calculator", description="Performs arithmetic calculations. Use this for any math problems.")
def calc(expression: str) -> str:
    """Evaluate mathematical expressions."""
    return str(eval(expression))
```

### é«˜çº§æ¨¡å¼å®šä¹‰

ä½¿ç”¨ Pydantic æ¨¡å‹æˆ– JSON æ¨¡å¼å®šä¹‰å¤æ‚è¾“å…¥ï¼š

<CodeGroup>
    ```python Pydantic model
    from pydantic import BaseModel, Field
    from typing import Literal

    class WeatherInput(BaseModel):
        """Input for weather queries."""
        location: str = Field(description="City name or coordinates")
        units: Literal["celsius", "fahrenheit"] = Field(
            default="celsius",
            description="Temperature unit preference"
        )
        include_forecast: bool = Field(
            default=False,
            description="Include 5-day forecast"
        )

    @tool(args_schema=WeatherInput)
    def get_weather(location: str, units: str = "celsius", include_forecast: bool = False) -> str:
        """Get current weather and optional forecast."""
        temp = 22 if units == "celsius" else 72
        result = f"Current weather in {location}: {temp} degrees {units[0].upper()}"
        if include_forecast:
            result += "\nNext 5 days: Sunny"
        return result
    ```

    ```python JSON Schema
    weather_schema = {
        "type": "object",
        "properties": {
            "location": {"type": "string"},
            "units": {"type": "string"},
            "include_forecast": {"type": "boolean"}
        },
        "required": ["location", "units", "include_forecast"]
    }

    @tool(args_schema=weather_schema)
    def get_weather(location: str, units: str = "celsius", include_forecast: bool = False) -> str:
        """Get current weather and optional forecast."""
        temp = 22 if units == "celsius" else 72
        result = f"Current weather in {location}: {temp} degrees {units[0].upper()}"
        if include_forecast:
            result += "\nNext 5 days: Sunny"
        return result
    ```
</CodeGroup>


## è®¿é—®ä¸Šä¸‹æ–‡

<Info>
**ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦ï¼š**å½“å·¥å…·å¯ä»¥è®¿é—®ä»£ç†çŠ¶æ€ã€è¿è¡Œæ—¶ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†æ—¶ï¼Œå®ƒä»¬æœ€å¼ºå¤§ã€‚è¿™ä½¿å·¥å…·èƒ½å¤Ÿåšå‡ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å†³ç­–ã€ä¸ªæ€§åŒ–å“åº”å¹¶åœ¨å¯¹è¯ä¹‹é—´ç»´æŠ¤ä¿¡æ¯ã€‚

è¿è¡Œæ—¶ä¸Šä¸‹æ–‡æä¾›äº†ä¸€ç§åœ¨è¿è¡Œæ—¶å°†ä¾èµ–é¡¹ï¼ˆå¦‚æ•°æ®åº“è¿æ¥ã€ç”¨æˆ· ID æˆ–é…ç½®ï¼‰æ³¨å…¥åˆ°å·¥å…·ä¸­çš„æ–¹æ³•ï¼Œä½¿å®ƒä»¬æ›´å…·å¯æµ‹è¯•æ€§å’Œå¯é‡ç”¨æ€§ã€‚



</Info>

å·¥å…·å¯ä»¥é€šè¿‡ `ToolRuntime` å‚æ•°è®¿é—®è¿è¡Œæ—¶ä¿¡æ¯ï¼Œå®ƒæä¾›ï¼š

- **State** - åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æµåŠ¨çš„å¯å˜æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œæ¶ˆæ¯ã€è®¡æ•°å™¨ã€è‡ªå®šä¹‰å­—æ®µï¼‰
- **Context** - ä¸å¯å˜é…ç½®ï¼Œå¦‚ç”¨æˆ· IDã€ä¼šè¯è¯¦ç»†ä¿¡æ¯æˆ–ç‰¹å®šäºåº”ç”¨ç¨‹åºçš„é…ç½®
- **Store** - è·¨å¯¹è¯çš„æŒä¹…é•¿æœŸè®°å¿†
- **Stream Writer** - åœ¨å·¥å…·æ‰§è¡Œæ—¶æµå¼ä¼ è¾“è‡ªå®šä¹‰æ›´æ–°
- **Config** - æ‰§è¡Œçš„ `RunnableConfig`
- **Tool Call ID** - å½“å‰å·¥å…·è°ƒç”¨çš„ ID

```mermaid
graph LR
    %% Runtime Context
    subgraph "ğŸ”§ Tool Runtime Context"
        A[Tool Call] --> B[ToolRuntime]
        B --> C[State Access]
        B --> D[Context Access]
        B --> E[Store Access]
        B --> F[Stream Writer]
    end

    %% Available Resources
    subgraph "ğŸ“Š Available Resources"
        C --> G[Messages]
        C --> H[Custom State]
        D --> I[User ID]
        D --> J[Session Info]
        E --> K[Long-term Memory]
        E --> L[User Preferences]
    end

    %% Tool Capabilities
    subgraph "âš¡ Enhanced Tool Capabilities"
        M[Context-Aware Tools]
        N[Stateful Tools]
        O[Memory-Enabled Tools]
        P[Streaming Tools]
    end

    %% Connections
    G --> M
    H --> N
    I --> M
    J --> M
    K --> O
    L --> O
    F --> P
```

### `ToolRuntime`

ä½¿ç”¨ `ToolRuntime` åœ¨å•ä¸ªå‚æ•°ä¸­è®¿é—®æ‰€æœ‰è¿è¡Œæ—¶ä¿¡æ¯ã€‚åªéœ€å°† `runtime: ToolRuntime` æ·»åŠ åˆ°å·¥å…·ç­¾åä¸­ï¼Œå®ƒå°†è‡ªåŠ¨æ³¨å…¥ï¼Œè€Œä¸ä¼šæš´éœ²ç»™ LLMã€‚

<Info>
**`ToolRuntime`**ï¼šä¸€ä¸ªç»Ÿä¸€çš„å‚æ•°ï¼Œä¸ºå·¥å…·æä¾›å¯¹çŠ¶æ€ã€ä¸Šä¸‹æ–‡ã€å­˜å‚¨ã€æµå¼ä¼ è¾“ã€é…ç½®å’Œå·¥å…·è°ƒç”¨ ID çš„è®¿é—®ã€‚è¿™å–ä»£äº†ä½¿ç”¨å•ç‹¬çš„ [`InjectedState`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedState)ã€[`InjectedStore`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedStore)ã€[`get_runtime`](https://reference.langchain.com/python/langgraph/runtime/#langgraph.runtime.get_runtime) å’Œ [`InjectedToolCallId`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.InjectedToolCallId) æ³¨é‡Šçš„æ—§æ¨¡å¼ã€‚

è¿è¡Œæ—¶è‡ªåŠ¨ä¸ºæ‚¨çš„å·¥å…·å‡½æ•°æä¾›è¿™äº›åŠŸèƒ½ï¼Œè€Œæ— éœ€æ‚¨æ˜¾å¼ä¼ é€’å®ƒä»¬æˆ–ä½¿ç”¨å…¨å±€çŠ¶æ€ã€‚
</Info>

**è®¿é—®çŠ¶æ€ï¼š**

å·¥å…·å¯ä»¥ä½¿ç”¨ `ToolRuntime` è®¿é—®å½“å‰å›¾çŠ¶æ€ï¼š

```python
from langchain.tools import tool, ToolRuntime

# è®¿é—®å½“å‰å¯¹è¯çŠ¶æ€
@tool
def summarize_conversation(
    runtime: ToolRuntime
) -> str:
    """Summarize the conversation so far."""
    messages = runtime.state["messages"]

    human_msgs = sum(1 for m in messages if m.__class__.__name__ == "HumanMessage")
    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == "AIMessage")
    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == "ToolMessage")

    return f"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results"

# è®¿é—®è‡ªå®šä¹‰çŠ¶æ€å­—æ®µ
@tool
def get_user_preference(
    pref_name: str,
    runtime: ToolRuntime  # ToolRuntime å‚æ•°å¯¹æ¨¡å‹ä¸å¯è§
) -> str:
    """Get a user preference value."""
    preferences = runtime.state.get("user_preferences", {})
    return preferences.get(pref_name, "Not set")
```

<Warning>
`tool_runtime` å‚æ•°å¯¹æ¨¡å‹éšè—ã€‚å¯¹äºä¸Šé¢çš„ç¤ºä¾‹ï¼Œæ¨¡å‹åœ¨å·¥å…·æ¨¡å¼ä¸­åªçœ‹åˆ° `pref_name` - `tool_runtime` *ä¸*åŒ…å«åœ¨è¯·æ±‚ä¸­ã€‚
</Warning>

**æ›´æ–°çŠ¶æ€ï¼š**

ä½¿ç”¨ [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) æ›´æ–°ä»£ç†çš„çŠ¶æ€æˆ–æ§åˆ¶å›¾çš„æ‰§è¡Œæµï¼š

```python
from langgraph.types import Command
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langchain.tools import tool, ToolRuntime

# é€šè¿‡åˆ é™¤æ‰€æœ‰æ¶ˆæ¯æ¥æ›´æ–°å¯¹è¯å†å²
@tool
def clear_conversation() -> Command:
    """Clear the conversation history."""

    return Command(
        update={
            "messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],
        }
    )

# æ›´æ–°ä»£ç†çŠ¶æ€ä¸­çš„ user_name
@tool
def update_user_name(
    new_name: str,
    runtime: ToolRuntime
) -> Command:
    """Update the user's name."""
    return Command(update={"user_name": new_name})
```


#### ä¸Šä¸‹æ–‡

é€šè¿‡ `runtime.context` è®¿é—®ä¸å¯å˜é…ç½®å’Œä¸Šä¸‹æ–‡æ•°æ®ï¼Œå¦‚ç”¨æˆ· IDã€ä¼šè¯è¯¦ç»†ä¿¡æ¯æˆ–ç‰¹å®šäºåº”ç”¨ç¨‹åºçš„é…ç½®ã€‚

å·¥å…·å¯ä»¥é€šè¿‡ `ToolRuntime` è®¿é—®è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼š

```python
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime


USER_DATABASE = {
    "user123": {
        "name": "Alice Johnson",
        "account_type": "Premium",
        "balance": 5000,
        "email": "alice@example.com"
    },
    "user456": {
        "name": "Bob Smith",
        "account_type": "Standard",
        "balance": 1200,
        "email": "bob@example.com"
    }
}

@dataclass
class UserContext:
    user_id: str

@tool
def get_account_info(runtime: ToolRuntime[UserContext]) -> str:
    """Get the current user's account information."""
    user_id = runtime.context.user_id

    if user_id in USER_DATABASE:
        user = USER_DATABASE[user_id]
        return f"Account holder: {user['name']}\nType: {user['account_type']}\nBalance: ${user['balance']}"
    return "User not found"

model = ChatOpenAI(model="gpt-4o")
agent = create_agent(
    model,
    tools=[get_account_info],
    context_schema=UserContext,
    system_prompt="You are a financial assistant."
)

result = agent.invoke(
    {"messages": [{"role": "user", "content": "What's my current balance?"}]},
    context=UserContext(user_id="user123")
)
```




#### è®°å¿†ï¼ˆå­˜å‚¨ï¼‰

ä½¿ç”¨å­˜å‚¨è®¿é—®è·¨å¯¹è¯çš„æŒä¹…æ•°æ®ã€‚å­˜å‚¨é€šè¿‡ `runtime.store` è®¿é—®ï¼Œå…è®¸æ‚¨ä¿å­˜å’Œæ£€ç´¢ç‰¹å®šäºç”¨æˆ·æˆ–ç‰¹å®šäºåº”ç”¨ç¨‹åºçš„æ•°æ®ã€‚

å·¥å…·å¯ä»¥é€šè¿‡ `ToolRuntime` è®¿é—®å’Œæ›´æ–°å­˜å‚¨ï¼š

```python expandable
from typing import Any
from langgraph.store.memory import InMemoryStore
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime


# è®¿é—®è®°å¿†
@tool
def get_user_info(user_id: str, runtime: ToolRuntime) -> str:
    """Look up user info."""
    store = runtime.store
    user_info = store.get(("users",), user_id)
    return str(user_info.value) if user_info else "Unknown user"

# æ›´æ–°è®°å¿†
@tool
def save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:
    """Save user info."""
    store = runtime.store
    store.put(("users",), user_id, user_info)
    return "Successfully saved user info."

store = InMemoryStore()
agent = create_agent(
    model,
    tools=[get_user_info, save_user_info],
    store=store
)

# ç¬¬ä¸€æ¬¡ä¼šè¯ï¼šä¿å­˜ç”¨æˆ·ä¿¡æ¯
agent.invoke({
    "messages": [{"role": "user", "content": "Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev"}]
})

# ç¬¬äºŒæ¬¡ä¼šè¯ï¼šè·å–ç”¨æˆ·ä¿¡æ¯
agent.invoke({
    "messages": [{"role": "user", "content": "Get user info for user with id 'abc123'"}]
})
# Here is the user info for user with ID "abc123":
# - Name: Foo
# - Age: 25
# - Email: foo@langchain.dev
```




#### æµå¼å†™å…¥å™¨

ä½¿ç”¨ `runtime.stream_writer` åœ¨å·¥å…·æ‰§è¡Œæ—¶æµå¼ä¼ è¾“è‡ªå®šä¹‰æ›´æ–°ã€‚è¿™å¯¹äºå‘ç”¨æˆ·æä¾›æœ‰å…³å·¥å…·æ­£åœ¨æ‰§è¡Œçš„æ“ä½œçš„å®æ—¶åé¦ˆå¾ˆæœ‰ç”¨ã€‚

```python
from langchain.tools import tool, ToolRuntime

@tool
def get_weather(city: str, runtime: ToolRuntime) -> str:
    """Get weather for a given city."""
    writer = runtime.stream_writer

    # åœ¨å·¥å…·æ‰§è¡Œæ—¶æµå¼ä¼ è¾“è‡ªå®šä¹‰æ›´æ–°
    writer(f"Looking up data for city: {city}")
    writer(f"Acquired data for city: {city}")

    return f"It's always sunny in {city}!"
```

<Note>
å¦‚æœæ‚¨åœ¨å·¥å…·å†…ä½¿ç”¨ `runtime.stream_writer`ï¼Œåˆ™å¿…é¡»åœ¨ LangGraph æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­è°ƒç”¨è¯¥å·¥å…·ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æµå¼ä¼ è¾“](/oss/python/langchain/streaming)ã€‚
</Note>

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\langchain\tools.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
