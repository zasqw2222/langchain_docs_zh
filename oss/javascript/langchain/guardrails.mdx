---
title: 防护栏
description: 为您的代理实现安全检查与内容过滤
---



防护栏通过在代理执行的关键点验证和过滤内容，帮助您构建安全、合规的 AI 应用。它们可以检测敏感信息、执行内容策略、验证输出，并在不安全行为造成问题之前进行预防。

常见用例包括：
- 防止 PII 泄露
- 检测并阻止提示注入攻击
- 阻止不当或有害内容
- 执行业务规则和合规要求
- 验证输出质量和准确性

您可以使用[中间件](/oss/javascript/langchain/middleware)在战略要点拦截执行来实现防护栏——在代理启动之前、完成之后，或围绕模型和工具调用。

<div style={{ display: "flex", justifyContent: "center" }}>
  <img
    src="/oss/images/middleware_final.png"
    alt="Middleware flow diagram"
    className="rounded-lg"
  />
</div>

防护栏可以使用两种互补的方法实现：

<CardGroup cols={2}>
  <Card title="确定性防护栏" icon="list-check">
    使用基于规则的逻辑，如正则表达式模式、关键词匹配或显式检查。快速、可预测且成本效益高，但可能遗漏细微的违规行为。
  </Card>
  <Card title="基于模型的防护栏" icon="brain">
    使用 LLM 或分类器通过语义理解评估内容。能捕获规则遗漏的细微问题，但速度较慢且成本更高。
  </Card>
</CardGroup>

LangChain 提供内置防护栏（例如，[PII 检测](#pii-detection)、[人工介入](#human-in-the-loop)）和灵活的中间件系统，用于使用任一方法构建自定义防护栏。

## 内置防护栏

### PII 检测

LangChain 提供内置中间件，用于检测和处理对话中的个人身份信息（PII）。此中间件可以检测常见的 PII 类型，如电子邮件、信用卡、IP 地址等。

PII 检测中间件适用于有合规要求的医疗和金融应用、需要清理日志的客户服务代理，以及任何处理敏感用户数据的应用。

PII 中间件支持多种处理检测到的 PII 的策略：

| 策略 | 描述 | 示例 |
|----------|-------------|---------|
| `redact` | 替换为 `[REDACTED_TYPE]` | `[REDACTED_EMAIL]` |
| `mask` | 部分遮蔽（例如，最后 4 位数字） | `****-****-****-1234` |
| `hash` | 替换为确定性哈希 | `a8f5f167...` |
| `block` | 检测到时抛出异常 | 抛出错误 |



```typescript
import { createAgent, piiRedactionMiddleware } from "langchain";

const agent = createAgent({
  model: "gpt-4o",
  tools: [customerServiceTool, emailTool],
  middleware: [
    // Redact emails in user input before sending to model
    piiRedactionMiddleware({
      piiType: "email",
      strategy: "redact",
      applyToInput: true,
    }),
    // Mask credit cards in user input
    piiRedactionMiddleware({
      piiType: "credit_card",
      strategy: "mask",
      applyToInput: true,
    }),
    // Block API keys - raise error if detected
    piiRedactionMiddleware({
      piiType: "api_key",
      detector: /sk-[a-zA-Z0-9]{32}/,
      strategy: "block",
      applyToInput: true,
    }),
  ],
});

// 当用户提供 PII 时，将根据策略进行处理
const result = await agent.invoke({
  messages: [{
    role: "user",
    content: "My email is john.doe@example.com and card is 5105-1051-0510-5100"
  }]
});
```


<Accordion title="内置 PII 类型和配置">

**内置 PII 类型：**
- `email` - 电子邮件地址
- `credit_card` - 信用卡号（Luhn 验证）
- `ip` - IP 地址
- `mac_address` - MAC 地址
- `url` - URL

**配置选项：**



Parameter | Description | Default
-----------|-------------|---------
`piiType` | Type of PII to detect (built-in or custom) | Required
`strategy` | How to handle detected PII (`"block"`, `"redact"`, `"mask"`, `"hash"`) | `"redact"`
`detector` | Custom detector regex pattern | `undefined` (uses built-in)
`applyToInput` | Check user messages before model call | `true`
`applyToOutput` | Check AI messages after model call | `false`
`applyToToolResults` | Check tool result messages after execution | `false`


</Accordion>

有关 PII 检测功能的完整详细信息，请参阅[中间件文档](/oss/javascript/langchain/middleware#pii-detection)。

### 人工介入

LangChain 提供内置中间件，要求在执行敏感操作之前获得人工批准。这是高风险决策最有效的防护栏之一。

人工介入中间件适用于金融交易和转账、删除或修改生产数据、向外部发送通信以及任何具有重大业务影响的操作。



```typescript
import { createAgent, humanInTheLoopMiddleware } from "langchain";
import { MemorySaver, Command } from "@langchain/langgraph";

const agent = createAgent({
  model: "gpt-4o",
  tools: [searchTool, sendEmailTool, deleteDatabaseTool],
  middleware: [
    humanInTheLoopMiddleware({
      interruptOn: {
        // 需要批准敏感操作
        send_email: { allowAccept: true, allowEdit: true, allowRespond: true },
        delete_database: { allowAccept: true, allowEdit: true, allowRespond: true },
        // 自动批准安全操作
        search: false,
      }
    }),
  ],
  checkpointer: new MemorySaver(),
});

// 人工介入需要线程 ID 以进行持久化
const config = { configurable: { thread_id: "some_id" } };

// 代理将在执行敏感工具之前暂停并等待批准
let result = await agent.invoke(
  { messages: [{ role: "user", content: "Send an email to the team" }] },
  config
);

result = await agent.invoke(
  new Command({ resume: { decisions: [{ type: "approve" }] } }),
  config  // 相同的线程 ID 以恢复暂停的对话
);
```


<Tip>
    有关实现批准工作流的完整详细信息，请参阅[人工介入文档](/oss/javascript/langchain/human-in-the-loop)。
</Tip>

## 自定义防护栏

对于更复杂的防护栏，您可以创建在代理执行之前或之后运行的自定义中间件。这使您可以完全控制验证逻辑、内容过滤和安全检查。

### 代理前防护栏

使用"代理前"钩子在每次调用的开始时验证请求一次。这对于会话级检查很有用，如身份验证、速率限制或在任何处理开始之前阻止不当请求。



```typescript
import { createMiddleware, AIMessage } from "langchain";

const contentFilterMiddleware = (bannedKeywords: string[]) => {
  const keywords = bannedKeywords.map(kw => kw.toLowerCase());

  return createMiddleware({
    name: "ContentFilterMiddleware",
    beforeAgent: (state) => {
      // 获取第一条用户消息
      if (!state.messages || state.messages.length === 0) {
        return;
      }

      const firstMessage = state.messages[0];
      if (firstMessage._getType() !== "human") {
        return;
      }

      const content = firstMessage.content.toString().toLowerCase();

      // 检查禁用关键词
      for (const keyword of keywords) {
        if (content.includes(keyword)) {
          // 在任何处理之前阻止执行
          return {
            messages: [
              new AIMessage(
                "I cannot process requests containing inappropriate content. Please rephrase your request."
              )
            ],
            jumpTo: "end",
          };
        }
      }

      return;
    },
  });
};

// 使用自定义防护栏
import { createAgent } from "langchain";

const agent = createAgent({
  model: "gpt-4o",
  tools: [searchTool, calculatorTool],
  middleware: [
    contentFilterMiddleware(["hack", "exploit", "malware"]),
  ],
});

// 此请求将在任何处理之前被阻止
const result = await agent.invoke({
  messages: [{ role: "user", content: "How do I hack into a database?" }]
});
```


### 代理后防护栏

使用"代理后"钩子在返回给用户之前验证最终输出一次。这对于基于模型的安全检查、质量验证或对完整代理响应的最终合规扫描很有用。



```typescript
import { createMiddleware, AIMessage, initChatModel } from "langchain";

const safetyGuardrailMiddleware = () => {
  const safetyModel = initChatModel("gpt-4o-mini");

  return createMiddleware({
    name: "SafetyGuardrailMiddleware",
    afterAgent: async (state) => {
      // 获取最终的 AI 响应
      if (!state.messages || state.messages.length === 0) {
        return;
      }

      const lastMessage = state.messages[state.messages.length - 1];
      if (lastMessage._getType() !== "ai") {
        return;
      }

      // 使用模型评估安全性
      const safetyPrompt = `Evaluate if this response is safe and appropriate.
      Respond with only 'SAFE' or 'UNSAFE'.

      Response: ${lastMessage.content.toString()}`;

      const result = await safetyModel.invoke([
        { role: "user", content: safetyPrompt }
      ]);

      if (result.content.toString().includes("UNSAFE")) {
        return {
          messages: [
            new AIMessage(
              "I cannot provide that response. Please rephrase your request."
            )
          ],
          jumpTo: "end",
        };
      }

      return;
    },
  });
};

// 使用安全防护栏
import { createAgent } from "langchain";

const agent = createAgent({
  model: "gpt-4o",
  tools: [searchTool, calculatorTool],
  middleware: [safetyGuardrailMiddleware()],
});

const result = await agent.invoke({
  messages: [{ role: "user", content: "How do I make explosives?" }]
});
```


### 组合多个防护栏

您可以通过将多个防护栏添加到中间件数组中来堆叠它们。它们按顺序执行，允许您构建分层保护：



```typescript
import { createAgent, piiRedactionMiddleware, humanInTheLoopMiddleware } from "langchain";

const agent = createAgent({
  model: "gpt-4o",
  tools: [searchTool, sendEmailTool],
  middleware: [
    // 第 1 层：确定性输入过滤器（代理前）
    contentFilterMiddleware(["hack", "exploit"]),

    // 第 2 层：PII 保护（模型前后）
    piiRedactionMiddleware({
      piiType: "email",
      strategy: "redact",
      applyToInput: true,
    }),
    piiRedactionMiddleware({
      piiType: "email",
      strategy: "redact",
      applyToOutput: true,
    }),

    // 第 3 层：敏感工具的人工批准
    humanInTheLoopMiddleware({
      interruptOn: {
        send_email: { allowAccept: true, allowEdit: true, allowRespond: true },
      }
    }),

    // 第 4 层：基于模型的安全检查（代理后）
    safetyGuardrailMiddleware(),
  ],
});
```


## 其他资源

- [中间件文档](/oss/javascript/langchain/middleware) - 自定义中间件完整指南
- [中间件 API 参考](https://reference.langchain.com/python/langchain/middleware/) - 自定义中间件完整指南
- [人工介入](/oss/javascript/langchain/human-in-the-loop) - 为敏感操作添加人工审查
- [测试代理](/oss/javascript/langchain/test) - 测试安全机制的策略

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\langchain\guardrails.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
