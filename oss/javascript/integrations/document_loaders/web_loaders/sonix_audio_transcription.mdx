---
title: Sonix Audio
---

<Tip>
**Compatibility**

Only available on Node.js.
</Tip>

This covers how to load document objects from an audio file using the [Sonix](https://sonix.ai/) API.

## Setup

To run this loader you will need to create an account on the https://sonix.ai/ and obtain an auth key from the https://my.sonix.ai/api page.

You'll also need to install the `sonix-speech-recognition` library:

```bash npm
npm install @langchain/community @langchain/core sonix-speech-recognition
```

## Usage

Once auth key is configured, you can use the loader to create transcriptions and then convert them into a Document.
In the `request` parameter, you can either specify a local file by setting `audioFilePath` or a remote file using `audioUrl`.
You will also need to specify the audio language. See the list of supported languages [here](https://sonix.ai/docs/api#languages).

```typescript
import { SonixAudioTranscriptionLoader } from "@langchain/community/document_loaders/web/sonix_audio";

const loader = new SonixAudioTranscriptionLoader({
  sonixAuthKey: "SONIX_AUTH_KEY",
  request: {
    audioFilePath: "LOCAL_AUDIO_FILE_PATH",
    fileName: "FILE_NAME",
    language: "en",
  },
});

const docs = await loader.load();

console.log(docs);
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\document_loaders\web_loaders\sonix_audio_transcription.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
