---
title: HyDE Retriever
---

This example shows how to use the HyDE Retriever, which implements Hypothetical Document Embeddings (HyDE) as described in [this paper](https://arxiv.org/abs/2212.10496).

At a high level, HyDE is an embedding technique that takes queries, generates a hypothetical answer, and then embeds that generated document and uses that as the final example.

In order to use HyDE, we therefore need to provide a base embedding model, as well as an LLM that can be used to generate those documents. By default, the HyDE class comes with some default prompts to use (see the paper for more details on them), but we can also create our own, which should have a single input variable `{question}`.

## Usage

```typescript
import { OpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";
import { HydeRetriever } from "@langchain/classic/retrievers/hyde";
import { Document } from "@langchain/core/documents";

const embeddings = new OpenAIEmbeddings();
const vectorStore = new MemoryVectorStore(embeddings);
const llm = new OpenAI();
const retriever = new HydeRetriever({
  vectorStore,
  llm,
  k: 1,
});

await vectorStore.addDocuments(
  [
    "My name is John.",
    "My name is Bob.",
    "My favourite food is pizza.",
    "My favourite food is pasta.",
  ].map((pageContent) => new Document({ pageContent }))
);

const results = await retriever.invoke("What is my favourite food?");

console.log(results);
/*
[
  Document { pageContent: 'My favourite food is pasta.', metadata: {} }
]
*/
```

## Related

- [Retrieval guide](/oss/javascript/langchain/retrieval)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\retrievers\hyde.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
