---
title: CloudflareWorkersAI
---

This will help you get started with Cloudflare Workers AI text completion models (LLMs) using LangChain. For detailed documentation on `CloudflareWorkersAI` features and configuration options, please refer to the [API reference](https://api.js.langchain.com/classes/langchain_cloudflare.CloudflareWorkersAI.html).

## Overview

### Integration details

| Class | Package | Local | Serializable | PY support | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [`CloudflareWorkersAI`](https://api.js.langchain.com/classes/langchain_cloudflare.CloudflareWorkersAI.html) | [`@langchain/cloudflare`](https://npmjs.com/@langchain/cloudflare) | ❌ | ✅ | ❌ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/cloudflare?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/cloudflare?style=flat-square&label=%20&) |

## Setup

To access Cloudflare Workers AI models you'll need to create a Cloudflare account, get an API key, and install the `@langchain/cloudflare` integration package.

### Credentials

Head [to this page](https://developers.cloudflare.com/workers-ai/) to sign up to Cloudflare and generate an API key. Once you've done this, note your `CLOUDFLARE_ACCOUNT_ID` and `CLOUDFLARE_API_TOKEN`.

### Installation

The LangChain Cloudflare integration lives in the `@langchain/cloudflare` package:

<CodeGroup>
```bash npm
npm install @langchain/cloudflare @langchain/core
```
```bash yarn
yarn add @langchain/cloudflare @langchain/core
```
```bash pnpm
pnpm add @langchain/cloudflare @langchain/core
```
</CodeGroup>

## Instantiation

Now we can instantiate our model object and generate chat completions:

```typescript
// @lc-docs-hide-cell

// @ts-expect-error Deno is not recognized
const CLOUDFLARE_ACCOUNT_ID = Deno.env.get("CLOUDFLARE_ACCOUNT_ID");
// @ts-expect-error Deno is not recognized
const CLOUDFLARE_API_TOKEN = Deno.env.get("CLOUDFLARE_API_TOKEN");
```

```typescript
import { CloudflareWorkersAI } from "@langchain/cloudflare";

const llm = new CloudflareWorkersAI({
  model: "@cf/meta/llama-3.1-8b-instruct", // Default value
  cloudflareAccountId: CLOUDFLARE_ACCOUNT_ID,
  cloudflareApiToken: CLOUDFLARE_API_TOKEN,
  // Pass a custom base URL to use Cloudflare AI Gateway
  // baseUrl: `https://gateway.ai.cloudflare.com/v1/{YOUR_ACCOUNT_ID}/{GATEWAY_NAME}/workers-ai/`,
});
```

## Invocation

```typescript
const inputText = "Cloudflare is an AI company that "

const completion = await llm.invoke(inputText);
completion
```

```output
"Cloudflare is not an AI company, but rather a content delivery network (CDN) and security company. T"... 876 more characters
```

---

## API reference

For detailed documentation of all `CloudflareWorkersAI` features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_cloudflare.CloudflareWorkersAI.html).

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\llms\cloudflare_workersai.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
