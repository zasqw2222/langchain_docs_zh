---
title: ChatDeepSeek
---


This will help you getting started with DeepSeek [chat models](/oss/javascript/langchain/models). For detailed documentation of all `ChatDeepSeek` features and configurations head to the [API reference](https://api.js.langchain.com/classes/_langchain_deepseek.ChatDeepSeek.html).

## Overview
### Integration details

| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/chat/deepseek) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [`ChatDeepSeek`](https://api.js.langchain.com/classes/_langchain_deepseek.ChatDeepSeek.html) | [`@langchain/deepseek`](https://npmjs.com/@langchain/deepseek) | ❌ (see [Ollama](/oss/javascript/integrations/chat/ollama)) | beta | ✅ | <img src="https://img.shields.io/npm/dm/@langchain/deepseek?style=flat-square&label=%20&" alt="NPM - Downloads" /> | <img src="https://img.shields.io/npm/v/@langchain/deepseek?style=flat-square&label=%20&" alt="NPM - Version" /> |

### Model features

See the links in the table headers below for guides on how to use specific features.

| [Tool calling](/oss/javascript/langchain/tools) | [Structured output](/oss/javascript/langchain/structured-output) | JSON mode | [Image input](/oss/javascript/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/javascript/langchain/streaming/) | [Token usage](/oss/javascript/langchain/models#token-usage) | [Logprobs](/oss/javascript/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ❌ | ❌ | ❌ | ✅ | ✅ | ✅ |

Note that as of 1/27/25, tool calling and structured output are not currently supported for `deepseek-reasoner`.

## Setup

To access DeepSeek models you'll need to create a DeepSeek account, get an API key, and install the `@langchain/deepseek` integration package.

You can also access the DeepSeek API through providers like [Together AI](/oss/javascript/integrations/chat/togetherai) or [Ollama](/oss/javascript/integrations/chat/ollama).

### Credentials

Head to https://deepseek.com/ to sign up to DeepSeek and generate an API key. Once you've done this set the `DEEPSEEK_API_KEY` environment variable:

```bash
export DEEPSEEK_API_KEY="your-api-key"
```

If you want to get automated tracing of your model calls you can also set your [LangSmith](/langsmith/home) API key by uncommenting below:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### Installation

The LangChain ChatDeepSeek integration lives in the `@langchain/deepseek` package:

<CodeGroup>
```bash npm
npm install @langchain/deepseek @langchain/core
```
```bash yarn
yarn add @langchain/deepseek @langchain/core
```
```bash pnpm
pnpm add @langchain/deepseek @langchain/core
```
</CodeGroup>

## Instantiation

Now we can instantiate our model object and generate chat completions:


```typescript
import { ChatDeepSeek } from "@langchain/deepseek";

const llm = new ChatDeepSeek({
  model: "deepseek-reasoner",
  temperature: 0,
  // other params...
})
```


```typescript
const aiMsg = await llm.invoke([
  [
    "system",
    "You are a helpful assistant that translates English to French. Translate the user sentence.",
  ],
  ["human", "I love programming."],
])
aiMsg
```
```output
AIMessage {
  "id": "e2874482-68a7-4552-8154-b6a245bab429",
  "content": "J'adore la programmation.",
  "additional_kwargs": {
    "reasoning_content": "..."
  },
  "response_metadata": {
    "tokenUsage": {
      "promptTokens": 23,
      "completionTokens": 7,
      "totalTokens": 30
    },
    "finish_reason": "stop",
    "model_name": "deepseek-reasoner",
    "usage": {
      "prompt_tokens": 23,
      "completion_tokens": 7,
      "total_tokens": 30,
      "prompt_tokens_details": {
        "cached_tokens": 0
      },
      "prompt_cache_hit_tokens": 0,
      "prompt_cache_miss_tokens": 23
    },
    "system_fingerprint": "fp_3a5770e1b4"
  },
  "tool_calls": [],
  "invalid_tool_calls": [],
  "usage_metadata": {
    "output_tokens": 7,
    "input_tokens": 23,
    "total_tokens": 30,
    "input_token_details": {
      "cache_read": 0
    },
    "output_token_details": {}
  }
}
```

```typescript
console.log(aiMsg.content)
```
```output
J'adore la programmation.
```

---

## API reference

For detailed documentation of all ChatDeepSeek features and configurations head to the API reference: https://api.js.langchain.com/classes/_langchain_deepseek.ChatDeepSeek.html

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\chat\deepseek.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
