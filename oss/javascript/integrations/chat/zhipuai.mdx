---
title: ChatZhipuAI
---

LangChain.js supports the Zhipu AI family of models.

https://open.bigmodel.cn/dev/howuse/model

## Setup

You'll need to sign up for an Zhipu API key and set it as an environment variable named `ZHIPUAI_API_KEY`

https://open.bigmodel.cn

You'll also need to install the following dependencies:

<Tip>
See [this section for general instructions on installing LangChain packages](/oss/javascript/langchain/install).
</Tip>

```bash npm
npm install @langchain/community @langchain/core jsonwebtoken
```

## Usage

Here's an example:

```typescript
import { ChatZhipuAI } from "@langchain/community/chat_models/zhipuai";
import { HumanMessage } from "@langchain/core/messages";

// Default model is glm-3-turbo
const glm3turbo = new ChatZhipuAI({
  zhipuAIApiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.ZHIPUAI_API_KEY
});

// Use glm-4
const glm4 = new ChatZhipuAI({
  model: "glm-4", // Available models:
  temperature: 1,
  zhipuAIApiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.ZHIPUAI_API_KEY
});

const messages = [new HumanMessage("Hello")];

const res = await glm3turbo.invoke(messages);
/*
AIMessage {
  content: "Hello! How can I help you today? Is there something you would like to talk about or ask about? I'm here to assist you with any questions you may have.",
}
*/

const res2 = await glm4.invoke(messages);
/*
AIMessage {
  text: "Hello! How can I help you today? Is there something you would like to talk about or ask about? I'm here to assist you with any questions you may have.",
}
*/
```

## Related

- Chat model [conceptual guide](/oss/javascript/langchain/models)
- Chat model [how-to guides](/oss/javascript/langchain/models)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\chat\zhipuai.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
