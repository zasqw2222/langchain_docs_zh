---
title: GoogleGenerativeAIEmbeddings
---

This will help you get started with Google Generative AI [embedding models](/oss/javascript/integrations/text_embedding) using LangChain. For detailed documentation on `GoogleGenerativeAIEmbeddings` features and configuration options, please refer to the [API reference](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html).

## Overview

### Integration details

| Class | Package | Local | [Py support](https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: |
| [`GoogleGenerativeAIEmbeddings`](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html) | [`@langchain/google-genai`](https://npmjs.com/@langchain/google-genai) | ❌ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/google-genai?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/google-genai?style=flat-square&label=%20&) |

## Setup

To access Google Generative AI embedding models you'll need to sign up for a Google AI account, get an API key, and install the `@langchain/google-genai` integration package.

### Credentials

Get an API key here: [ai.google.dev/tutorials/setup](https://ai.google.dev/tutorials/setup).

Next, set your key as an environment variable named `GOOGLE_API_KEY`:

```bash
export GOOGLE_API_KEY="your-api-key"
```

If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### Installation

The LangChain `GoogleGenerativeAIEmbeddings` integration lives in the `@langchain/google-genai` package. You may also wish to install the official SDK:

<CodeGroup>
```bash npm
npm install @langchain/google-genai @langchain/core @google/generative-ai
```
```bash yarn
yarn add @langchain/google-genai @langchain/core @google/generative-ai
```
```bash pnpm
pnpm add @langchain/google-genai @langchain/core @google/generative-ai
```
</CodeGroup>

## Instantiation

Now we can instantiate our model object and embed text:

```typescript
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { TaskType } from "@google/generative-ai";

const embeddings = new GoogleGenerativeAIEmbeddings({
  model: "gemini-embedding-001", // 768 dimensions
  taskType: TaskType.RETRIEVAL_DOCUMENT,
  title: "Document title",
});
```

## Indexing and Retrieval

Embedding models are often used in retrieval-augmented generation (RAG) flows, both as part of indexing data as well as later retrieving it. For more detailed instructions, please see our RAG tutorials under the [**Learn** tab](/oss/javascript/learn/).

Below, see how to index and retrieve data using the `embeddings` object we initialized above. In this example, we will index and retrieve a sample document using the demo [`MemoryVectorStore`](/oss/javascript/integrations/vectorstores/memory).

```typescript
// Create a vector store with a sample text
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";

const text = "LangChain is the framework for building context-aware reasoning applications";

const vectorstore = await MemoryVectorStore.fromDocuments(
  [{ pageContent: text, metadata: {} }],
  embeddings,
);

// Use the vector store as a retriever that returns a single document
const retriever = vectorstore.asRetriever(1);

// Retrieve the most similar text
const retrievedDocuments = await retriever.invoke("What is LangChain?");

retrievedDocuments[0].pageContent;
```

```output
LangChain is the framework for building context-aware reasoning applications
```

## Direct Usage

Under the hood, the vectorstore and retriever implementations are calling `embeddings.embedDocument(...)` and `embeddings.embedQuery(...)` to create embeddings for the text(s) used in `fromDocuments` and the retriever's `invoke` operations, respectively.

You can directly call these methods to get embeddings for your own use cases.

### Embed single texts

You can embed queries for search with `embedQuery`. This generates a vector representation specific to the query:

```typescript
const singleVector = await embeddings.embedQuery(text);

console.log(singleVector.slice(0, 100));
```

```output
[
  -0.018286658,   0.020051053,  -0.057487167,   0.0059406986, -0.0036901247,
  -0.010400916,    0.03396853,  -0.010867519,    0.015650319,   0.026443942,
   0.012251757,   -0.01581729,    0.02031182, -0.00062176475,  0.0065521155,
   -0.07107355,   0.033614952,    0.07109807,   -0.021078493,   0.048039366,
   0.022973344,    -0.0361746,   -0.04550704,   -0.048807852,    0.03414146,
   0.042450827,    0.02930612,   0.027274853,   -0.027707053,   -0.04167595,
    0.01708843,   0.028532283, -0.0018593844,      -0.096786,  -0.034648854,
  0.0013152987,   0.024425535,    0.04937838,    0.036890924,  -0.074619934,
  -0.028723065,   0.029158255,  -0.023993572,     0.03163398,   -0.02036324,
   -0.02333609,  -0.017407075, -0.0059643993,    -0.05564625,   0.051022638,
    0.03264913,  -0.008254581,  -0.030552095,    0.072952054,   -0.05448913,
   0.012030814,   -0.07978849,  -0.030417662,   0.0038343794,    0.03237516,
  -0.054259773,    -0.0524064,   -0.02145499,    0.006439614,    0.04988943,
   -0.03232189,    0.00990776,   -0.03863326,    -0.04979561,   0.009874035,
   -0.02617946,    0.02135152,  -0.070599854,     0.08655627,   -0.02080979,
  -0.014944934,  0.0034440767,  -0.035236854,    0.027093545,   0.032249685,
   -0.03559674,   0.046849757,    0.06965356,    0.028780492,    0.02865287,
   -0.07999455, -0.0058599655,  -0.050316703,   -0.018346578,  -0.038311094,
    0.08026719,   0.049136136,   -0.05372233,  -0.0062247813,    0.01791339,
   -0.03635157,  -0.031860247,  -0.031322744,    0.044055287,   0.034934316
]
```

### Embed multiple texts

You can embed multiple texts for indexing with `embedDocuments`. The internals used for this method may (but do not have to) differ from embedding queries:

```typescript
const text2 = "LangGraph is a library for building stateful, multi-actor applications with LLMs";

const vectors = await embeddings.embedDocuments([text, text2]);

console.log(vectors[0].slice(0, 100));
console.log(vectors[1].slice(0, 100));
```

```output
[
  -0.018286658,   0.020051053,  -0.057487167,   0.0059406986, -0.0036901247,
  -0.010400916,    0.03396853,  -0.010867519,    0.015650319,   0.026443942,
   0.012251757,   -0.01581729,    0.02031182, -0.00062176475,  0.0065521155,
   -0.07107355,   0.033614952,    0.07109807,   -0.021078493,   0.048039366,
   0.022973344,    -0.0361746,   -0.04550704,   -0.048807852,    0.03414146,
   0.042450827,    0.02930612,   0.027274853,   -0.027707053,   -0.04167595,
    0.01708843,   0.028532283, -0.0018593844,      -0.096786,  -0.034648854,
  0.0013152987,   0.024425535,    0.04937838,    0.036890924,  -0.074619934,
  -0.028723065,   0.029158255,  -0.023993572,     0.03163398,   -0.02036324,
   -0.02333609,  -0.017407075, -0.0059643993,    -0.05564625,   0.051022638,
    0.03264913,  -0.008254581,  -0.030552095,    0.072952054,   -0.05448913,
   0.012030814,   -0.07978849,  -0.030417662,   0.0038343794,    0.03237516,
  -0.054259773,    -0.0524064,   -0.02145499,    0.006439614,    0.04988943,
   -0.03232189,    0.00990776,   -0.03863326,    -0.04979561,   0.009874035,
   -0.02617946,    0.02135152,  -0.070599854,     0.08655627,   -0.02080979,
  -0.014944934,  0.0034440767,  -0.035236854,    0.027093545,   0.032249685,
   -0.03559674,   0.046849757,    0.06965356,    0.028780492,    0.02865287,
   -0.07999455, -0.0058599655,  -0.050316703,   -0.018346578,  -0.038311094,
    0.08026719,   0.049136136,   -0.05372233,  -0.0062247813,    0.01791339,
   -0.03635157,  -0.031860247,  -0.031322744,    0.044055287,   0.034934316
]
[
    0.011669316,    0.02170385,   -0.07519182,     0.003981285,
   0.0053525288,   0.008397044,   0.036672726,     0.016549919,
    0.061946314,    0.06280753,  -0.009199135,     0.014644887,
    0.046459496,  0.0122919325,  -0.013300706,    -0.051746193,
     -0.0490098,   0.045586824,   -0.05053146,     0.044294067,
   -0.012607168, -0.0071777054,  -0.048455723,    -0.075109236,
    0.013327612,  -0.025612017,   0.050875787,     0.030091539,
   -0.027163379,   -0.05760821,   0.014368641,    0.0044602253,
    0.035219245,  -0.033304706,  -0.045474708,    -0.038022216,
    0.012366698,   0.028978042,   0.038591366,     -0.10646444,
   -0.036803752,   0.018911313,   0.005681761,     0.025365992,
   -0.017165288, -0.0048005017,  -0.011460135,    0.0027811683,
    -0.04971402, -0.0019232291,    0.02141983,   -0.0013272346,
    -0.03337951,   0.030568397,   -0.05704511,     -0.01187748,
   -0.025354648,   0.016188234,  -0.022018699,    0.0096449675,
   -0.027020318,  -0.038059015,  -0.024455398,     0.021858294,
    0.010713859,   -0.07203855,   -0.05562406, 0.0000034690818,
   -0.054289237, -0.0027928432, -0.0010051605,     0.008493095,
   -0.064746305,   0.024419345,  -0.016629996,     -0.02686531,
    -0.02300653,   -0.03263113,   0.019998727,     0.029680967,
    -0.04365641,   0.013594972,   0.056486532,     0.025913332,
    0.025457978,  -0.048536208,   0.020046104,     -0.05857287,
   -0.032664414,  -0.032940287,    0.10053288,    -0.021389635,
  -0.0044220444,   0.037026003,    0.03142132,    -0.048912503,
    -0.07961264,  -0.051056523,   0.048032805,      0.04831778
]
```

---

## API reference

For detailed documentation of all `GoogleGenerativeAIEmbeddings` features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html).

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\text_embedding\google_generative_ai.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
