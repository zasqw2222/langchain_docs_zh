---
title: Momento Vector Index (MVI)
---

[MVI](https://gomomento.com): the most productive, easiest to use, serverless vector index for your data. To get started with MVI, simply sign up for an account. There's no need to handle infrastructure, manage servers, or be concerned about scaling. MVI is a service that scales automatically to meet your needs. Whether in Node.js, browser, or edge, Momento has you covered.

To sign up and access MVI, visit the [Momento Console](https://console.gomomento.com).

## Setup

1. Sign up for an API key in the [Momento Console](https://console.gomomento.com/).
2. Install the SDK for your environment.

   2.1. For **Node.js**:

   ```bash npm
   npm install @gomomento/sdk
   ```
   2.2. For **browser or edge environments**:

   ```bash npm
   npm install @gomomento/sdk-web
   ```

3. Setup Env variables for Momento before running the code

   3.1 OpenAI

   ```bash
   export OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
   ```

   3.2 Momento

   ```bash
   export MOMENTO_API_KEY=YOUR_MOMENTO_API_KEY_HERE # https://console.gomomento.com
   ```

## Usage

<Tip>
See [this section for general instructions on installing LangChain packages](/oss/javascript/langchain/install).
</Tip>

```bash npm
npm install @langchain/openai @langchain/community @langchain/core
```

### Index documents using `fromTexts` and search

This example demonstrates using the `fromTexts` method to instantiate the vector store and index documents.
If the index does not exist, then it will be created. If the index already exists, then the documents will be
added to the existing index.

The `ids` are optional; if you omit them, then Momento will generate UUIDs for you.

```typescript
import { MomentoVectorIndex } from "@langchain/community/vectorstores/momento_vector_index";
// For browser/edge, adjust this to import from "@gomomento/sdk-web";
import {
  PreviewVectorIndexClient,
  VectorIndexConfigurations,
  CredentialProvider,
} from "@gomomento/sdk";
import { OpenAIEmbeddings } from "@langchain/openai";
import { sleep } from "@langchain/classic/util/time";

const vectorStore = await MomentoVectorIndex.fromTexts(
  ["hello world", "goodbye world", "salutations world", "farewell world"],
  {},
  new OpenAIEmbeddings(),
  {
    client: new PreviewVectorIndexClient({
      configuration: VectorIndexConfigurations.Laptop.latest(),
      credentialProvider: CredentialProvider.fromEnvironmentVariable({
        environmentVariableName: "MOMENTO_API_KEY",
      }),
    }),
    indexName: "langchain-example-index",
  },
  { ids: ["1", "2", "3", "4"] }
);

// because indexing is async, wait for it to finish to search directly after
await sleep();

const response = await vectorStore.similaritySearch("hello", 2);

console.log(response);

/*
[
  Document { pageContent: 'hello world', metadata: {} },
  Document { pageContent: 'salutations world', metadata: {} }
]
*/
```

### Index documents using `fromDocuments` and search

Similar to the above, this example demonstrates using the `fromDocuments` method to instantiate the vector store and index documents.
If the index does not exist, then it will be created. If the index already exists, then the documents will be
added to the existing index.

Using `fromDocuments` allows you to seamlessly chain the various document loaders with indexing.

```typescript
import { MomentoVectorIndex } from "@langchain/community/vectorstores/momento_vector_index";
// For browser/edge, adjust this to import from "@gomomento/sdk-web";
import {
  PreviewVectorIndexClient,
  VectorIndexConfigurations,
  CredentialProvider,
} from "@gomomento/sdk";
import { OpenAIEmbeddings } from "@langchain/openai";
import { TextLoader } from "@langchain/classic/document_loaders/fs/text";
import { sleep } from "@langchain/classic/util/time";

// Create docs with a loader
const loader = new TextLoader("src/document_loaders/example_data/example.txt");
const docs = await loader.load();

const vectorStore = await MomentoVectorIndex.fromDocuments(
  docs,
  new OpenAIEmbeddings(),
  {
    client: new PreviewVectorIndexClient({
      configuration: VectorIndexConfigurations.Laptop.latest(),
      credentialProvider: CredentialProvider.fromEnvironmentVariable({
        environmentVariableName: "MOMENTO_API_KEY",
      }),
    }),
    indexName: "langchain-example-index",
  }
);

// because indexing is async, wait for it to finish to search directly after
await sleep();

// Search for the most similar document
const response = await vectorStore.similaritySearch("hello", 1);

console.log(response);
/*
[
  Document {
    pageContent: 'Foo\nBar\nBaz\n\n',
    metadata: { source: 'src/document_loaders/example_data/example.txt' }
  }
]
*/
```

### Search from an existing collection

```typescript
import { MomentoVectorIndex } from "@langchain/community/vectorstores/momento_vector_index";
// For browser/edge, adjust this to import from "@gomomento/sdk-web";
import {
  PreviewVectorIndexClient,
  VectorIndexConfigurations,
  CredentialProvider,
} from "@gomomento/sdk";
import { OpenAIEmbeddings } from "@langchain/openai";

const vectorStore = new MomentoVectorIndex(new OpenAIEmbeddings(), {
  client: new PreviewVectorIndexClient({
    configuration: VectorIndexConfigurations.Laptop.latest(),
    credentialProvider: CredentialProvider.fromEnvironmentVariable({
      environmentVariableName: "MOMENTO_API_KEY",
    }),
  }),
  indexName: "langchain-example-index",
});

const response = await vectorStore.similaritySearch("hello", 1);

console.log(response);
/*
[
  Document {
    pageContent: 'Foo\nBar\nBaz\n\n',
    metadata: { source: 'src/document_loaders/example_data/example.txt' }
  }
]
*/
```

## Related

- Vector store [conceptual guide](/oss/javascript/integrations/vectorstores)
- Vector store [how-to guides](/oss/javascript/integrations/vectorstores)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss\javascript\integrations\vectorstores\momento_vector_index.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
