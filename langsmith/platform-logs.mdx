---
title: View server logs for a trace
sidebarTitle: View server logs for a trace
---

When viewing a trace that was generated by a run in LangSmith, you can access the associated server logs directly from the trace view.

<Note>
Viewing server logs for a trace only works with the [Cloud SaaS](https://langchain-ai.github.io/langgra/langsmith/observability-concepts/deployment_options/#cloud-saas) and [fully self-hosted](https://langchain-ai.github.io/langgra/langsmith/observability-concepts/deployment_options/#self-hosted-control-plane) deployment options.
</Note>

## Access server logs from trace view

In the trace view, use the **See Logs** button in the top right corner, next to the **Run in Studio** button.

![](/langsmith/images/view-server-logs-button.png)

Clicking this button will take you to the server logs view for the associated deployment in LangSmith.

## Server logs view

The server logs view displays logs from both:

- **Agent Server's own operational logs** - Internal server operations, API calls, and system events
- **User application logs** - Logs written in your graph with:
  - Python: Use the `logging` or `structlog` libraries
  - JavaScript: Use the re-exported Winston logger from `@langchain/langgraph-sdk/logging`:

```javascript
import { getLogger } from "@langchain/langgraph-sdk/logging";

const logger = getLogger();
logger.info("Your log message");
```

## Filtering logs by trace ID

When you navigate from the trace view, the **Filters** box will automatically pre-fill with the Trace ID from the trace you just viewed.

This allows you to quickly filter the logs to see only those related to your specific trace execution.

![](/langsmith/images/lgp-server-logs-filters.png)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith\platform-logs.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>
